{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Due to computational limitations this Notebook has not been fully tested!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import h5py\n",
    "import os.path as osp\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Parameter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torch_geometric.data import HeteroData, Dataset, Data\n",
    "from torch_geometric.nn import GCNConv, HeteroConv, SAGEConv, GATConv, MessagePassing\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "# from torch_geometric.explain import Explainer, GNNExplainer\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words = nltk.corpus.stopwords.words('english')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = 'distilbert/distilbert-base-uncased'\n",
    "model = SentenceTransformer(model_name).to(device)\n",
    "# model = SentenceTransformer('anferico/bert-for-patents').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatentHeteroDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(PatentHeteroDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data = None\n",
    "        # processed_path = osp.join(self.processed_dir, self.processed_file_names)\n",
    "        # if osp.exists(processed_path):\n",
    "        #     self.data = torch.load(processed_path)\n",
    "        # else:\n",
    "        self.process()\n",
    "\n",
    "    @property\n",
    "    def num_classes(self):\n",
    "        return 2\n",
    "\n",
    "    @property\n",
    "    def raw_dir(self):\n",
    "        return '/mnt/hdd01/patentsview/Graph Neural Network for EDV-TEK Identification/raw//'\n",
    "    \n",
    "    @property\n",
    "    def processed_dir(self):\n",
    "        return '/mnt/hdd01/patentsview/Graph Neural Network for EDV-TEK Identification/processed/'\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [\n",
    "            'torch_tek_dataset_distilbert.h5' # Adjust to correct model\n",
    "        ]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return 'gnn_tek_data_distilbert.pt' # Adjust to correct model\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        # Initialize HeteroData object\n",
    "        data = HeteroData()\n",
    "    \n",
    "        # Open an HDF5 file\n",
    "        with h5py.File(osp.join(self.raw_dir, 'torch_tek_dataset_distilbert.h5'), 'r') as f:\n",
    "            # Load and process node features\n",
    "            data['patent'].x = torch.tensor(f['g_patent/x'][:], dtype=torch.float)\n",
    "            data['patent'].y = torch.tensor(f['g_patent/y'][:], dtype=torch.long)\n",
    "            data['author'].x = torch.tensor(f['g_author_nodes/x'][:], dtype=torch.float)\n",
    "            \n",
    "            # Load and process edge indices\n",
    "            data['patent', 'cites', 'patent'].edge_index = torch.tensor(f['patent_edge_index'][:], dtype=torch.long).t().contiguous()\n",
    "            data['author', 'author_of', 'patent'].edge_index = torch.tensor(f['person_patent_edge_index'][:], dtype=torch.long).t().contiguous()\n",
    "            data['patent', 'has_author', 'author'].edge_index = torch.tensor(f['patent_person_edge_index'][:], dtype=torch.long).t().contiguous()\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data = self.pre_transform(data)\n",
    "\n",
    "        # Create train_mask, val_mask, and test_mask\n",
    "        data['patent'].train_mask = torch.zeros(data['patent'].num_nodes, dtype=torch.bool)\n",
    "        data['patent'].val_mask = torch.zeros(data['patent'].num_nodes, dtype=torch.bool)\n",
    "        data['patent'].test_mask = torch.zeros(data['patent'].num_nodes, dtype=torch.bool)\n",
    "        data['patent'].train_mask[:int(0.8*data['patent'].num_nodes)] = 1\n",
    "        data['patent'].val_mask[int(0.8*data['patent'].num_nodes):int(0.9*data['patent'].num_nodes)] = 1\n",
    "        data['patent'].test_mask[int(0.9*data['patent'].num_nodes):] = 1\n",
    "\n",
    "        # Diagnostic print statements\n",
    "        print(\"Data keys after processing:\", data.keys())\n",
    "        print(\"Node types and their feature shapes:\")\n",
    "        for node_type, node_data in data.node_items():\n",
    "            print(f\"Node type: {node_type}\")\n",
    "            for key, item in node_data.items():\n",
    "                if key == 'x' or key == 'y':\n",
    "                    print(f\"Features ({key}) shape:\", item.size())\n",
    "\n",
    "        print(\"Edge types and their index shapes:\")\n",
    "        for edge_type, edge_data in data.edge_items():\n",
    "            print(f\"Edge type: {edge_type}\")\n",
    "            if 'edge_index' in edge_data:\n",
    "                print(\"Edge index shape:\", edge_data['edge_index'].size())\n",
    "            else:\n",
    "                print(f\"{edge_type} has no edge index.\")\n",
    "\n",
    "        self.data = data  # Save the processed data to self.data\n",
    "        torch.save(data, osp.join(self.processed_dir, self.processed_file_names))\n",
    "\n",
    "    def len(self):\n",
    "        return 1\n",
    "\n",
    "    def get(self, idx):\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PatentHeteroDataset(root='/mnt/hdd01/patentsview/Graph Neural Network for EDV-TEK Idnetification/')\n",
    "PatentDataset = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplifiedHeteroGCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_node_features_dict, num_classes):\n",
    "        super(SimplifiedHeteroGCN, self).__init__()\n",
    "        torch.manual_seed(42)  # For reproducible results\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(p=0.2)  # Define dropout layer\n",
    "\n",
    "        # Define a SAGEConv for essential relations\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('patent', 'cites', 'patent'): SAGEConv(num_node_features_dict['patent'], hidden_channels, add_self_loops=True)\n",
    "        }, aggr='mean')\n",
    "\n",
    "        self.conv2 = HeteroConv({\n",
    "            ('patent', 'cites', 'patent'): SAGEConv(hidden_channels, hidden_channels, add_self_loops=True)\n",
    "        }, aggr='mean')\n",
    "\n",
    "        # Linear layer for classifying patents\n",
    "        self.lin = torch.nn.Linear(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x_dict, edge_index_dict = data.x_dict, data.edge_index_dict\n",
    "        \n",
    "        # Apply dropout to 'patent' node features\n",
    "        x_dict['patent'] = self.dropout(x_dict['patent'])\n",
    "\n",
    "        # First convolution layer\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
    "        x_dict = {key: F.relu(x) for key, x in x_dict.items()}\n",
    "\n",
    "        # Second convolution layer\n",
    "        x_dict = self.conv2(x_dict, edge_index_dict)\n",
    "        x_dict = {key: F.relu(x) for key, x in x_dict.items()}\n",
    "\n",
    "        # Predictions for 'patent' node embeddings\n",
    "        out = self.lin(x_dict['patent'])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroGCN(MessagePassing):\n",
    "    def __init__(self, hidden_channels, num_node_features_dict, num_classes):\n",
    "        super(HeteroGCN, self).__init__(aggr='mean')\n",
    "        torch.manual_seed(42) # For reproducible results\n",
    "        \n",
    "        # Define a separate SAGEConv for each edge type with correct input feature sizes\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('patent', 'cites', 'patent'): SAGEConv(num_node_features_dict['patent'], hidden_channels, add_self_loops=True),\n",
    "            ('author', 'author_of', 'patent'): SAGEConv(num_node_features_dict['author'], hidden_channels, add_self_loops=True),\n",
    "            ('patent', 'has_author', 'author'): SAGEConv(num_node_features_dict['patent'], hidden_channels, add_self_loops=True)\n",
    "        }, aggr='mean')\n",
    "\n",
    "        self.conv2 = HeteroConv({\n",
    "            ('patent', 'cites', 'patent'): SAGEConv(hidden_channels, hidden_channels, add_self_loops=True),\n",
    "            ('author', 'author_of', 'patent'): SAGEConv(hidden_channels, hidden_channels, add_self_loops=True),\n",
    "            ('patent', 'has_author', 'author'): SAGEConv(hidden_channels, hidden_channels, add_self_loops=True)\n",
    "        }, aggr='mean')\n",
    "\n",
    "        # Linear layer for classifying patents\n",
    "        self.lin = torch.nn.Linear(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x_dict, edge_index_dict = data.x_dict, data.edge_index_dict\n",
    "\n",
    "        # Include dropout for regularization\n",
    "        x_dict['patent'] = F.dropout(x_dict['patent'], p=0.2, training=self.training)\n",
    "\n",
    "        # First convolution layer\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
    "        x_dict = {key: x.relu() for key, x in x_dict.items()}\n",
    "\n",
    "        # Second convolution layer\n",
    "        x_dict = self.conv2(x_dict, edge_index_dict)\n",
    "        x_dict = {key: x.relu() for key, x in x_dict.items()}\n",
    "\n",
    "        # Only use the 'patent' node embeddings for the final prediction\n",
    "        out = self.lin(x_dict['patent'])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_node_features_dict = {'patent': 768, 'author': 768}\n",
    "num_classes = 2\n",
    "\n",
    "# model = HeteroGCN(hidden_channels=64, num_node_features_dict=num_node_features_dict, num_classes=num_classes)\n",
    "# model = HeteroGCN(hidden_channels=512, num_node_features_dict=num_node_features_dict, num_classes=num_classes)\n",
    "# model = SimplifiedHeteroGCN(hidden_channels=512, num_node_features_dict=num_node_features_dict, num_classes=num_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "PatentDataset = PatentDataset.to(device)\n",
    "train_loader = NeighborLoader(PatentDataset, num_neighbors=[100], batch_size=512, shuffle=True, input_nodes=('patent', PatentDataset['patent'].train_mask))\n",
    "test_loader = NeighborLoader(PatentDataset, num_neighbors=[100], batch_size=512, shuffle=False, input_nodes=('patent', PatentDataset['patent'].test_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_batches = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        try:\n",
    "            out = model(batch) # For Heterogeneous NN\n",
    "            loss = criterion(out[batch['patent'].train_mask], batch['patent'].y[batch['patent'].train_mask]) # For Hetereogeneous NN \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_batches += 1\n",
    "        except Exception as e:\n",
    "            print(\"Error during training:\", e)\n",
    "            raise\n",
    "            \n",
    "    return total_loss / total_batches if total_batches else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch in test_loader:\n",
    "        batch = batch.to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(batch)\n",
    "            pred = out.argmax(dim=1)\n",
    "            \n",
    "            # Assuming batch['patent'].test_mask is a boolean mask\n",
    "            test_mask = batch['patent'].test_mask # For Hetereogeneous NN \n",
    "            test_labels = batch['patent'].y # For Hetereogeneous NN \n",
    "\n",
    "            # Update correct and total counts\n",
    "            correct += int((pred[test_mask] == test_labels[test_mask]).sum())\n",
    "            total += int(test_mask.sum())\n",
    "\n",
    "    test_acc = correct / total\n",
    "    return test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    loss = train()\n",
    "    test_acc = test()\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
