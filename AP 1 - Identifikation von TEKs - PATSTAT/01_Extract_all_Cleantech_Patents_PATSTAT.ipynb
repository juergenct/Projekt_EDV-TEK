{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sqlalchemy import create_engine, URL, text\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_object = URL.create(\n",
    "    drivername=\"\",\n",
    "    username=\"\",\n",
    "    password=\"\",\n",
    "    host=\"\",\n",
    "    port=\"\",\n",
    "    database=\"\"\n",
    ")\n",
    "engine = create_engine(url_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Indices on Query Columns (only required once!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_ep_index = \"\"\"CREATE INDEX ep_index ON ep_fulltext_data(epo_publn_nr, publn_auth);\"\"\"\n",
    "# query_us_brf_summary_index = \"\"\"CREATE INDEX us_brf_summary_index ON us_brf_summary(patent_id, publn_auth);\"\"\"\n",
    "# query_us_claims_index = \"\"\"CREATE INDEX us_claims_index ON us_claims(patent_id, publn_auth);\"\"\"\n",
    "# query_us_description_index = \"\"\"CREATE INDEX us_description_index ON us_description(patent_id, publn_auth);\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with engine.connect() as connection:\n",
    "#     connection.execute(text(query_ep_index))\n",
    "#     connection.execute(text(query_us_brf_summary_index))\n",
    "#     connection.execute(text(query_us_claims_index))\n",
    "#     connection.execute(text(query_us_description_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Cleantech Patents from PATSTAT (only granted and EP or US patents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPC Y02 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_cpc_index = \"\"\"CREATE INDEX idx_cpc_class_symbol ON tls224_appln_cpc(cpc_class_symbol);\"\"\" # only required once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_cpc_y02 = \"\"\"\n",
    "    SELECT a.appln_id, a.cpc_class_symbol\n",
    "    FROM tls224_appln_cpc a\n",
    "    JOIN tls201_appln b ON a.appln_id = b.appln_id\n",
    "    WHERE (a.cpc_class_symbol LIKE 'Y02A%' OR\n",
    "           a.cpc_class_symbol LIKE 'Y02B%' OR\n",
    "           a.cpc_class_symbol LIKE 'Y02C%' OR\n",
    "           a.cpc_class_symbol LIKE 'Y02D%' OR\n",
    "           a.cpc_class_symbol LIKE 'Y02E%' OR\n",
    "           a.cpc_class_symbol LIKE 'Y02P%' OR\n",
    "           a.cpc_class_symbol LIKE 'Y02T%' OR\n",
    "           a.cpc_class_symbol LIKE 'Y02W%')\n",
    "      AND b.appln_auth IN ('EP', 'US')\n",
    "      AND b.granted = 'Y';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as connection:\n",
    "    # connection.execute(text(query_cpc_index)) # Only required once\n",
    "    df_cpc = pd.read_sql_query(text(query_cpc_y02), connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPC Green Inventory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML Website IPC Green Inventory - Extract IPC Codes for Cleantech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_file = \"/home/thiesen/Documents/Projekt_EDV-TEK/IPC GREEN INVENTORY_komplett.html\"\n",
    "\n",
    "with open(html_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    html_content = file.read()\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "rows = soup.find_all(\"tr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipc_combined_text = []\n",
    "\n",
    "# Loop through table rows to extract the second column\n",
    "for row in rows:\n",
    "    ipc_column = row.find_all(\"td\")[1] if len(row.find_all(\"td\")) > 1 else None\n",
    "    if ipc_column:\n",
    "        combined_text = ipc_column.get_text(strip=True, separator=\" \")\n",
    "        if combined_text:  # Ensure the content is not empty\n",
    "            ipc_combined_text.append(combined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all white spaces before and after a hyphen\n",
    "ipc_combined_text = [re.sub(r\"\\s*-\\s*\", \"-\", text) for text in ipc_combined_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_ipc_codes(ipc_list):\n",
    "    expanded_codes = []\n",
    "    for entry in ipc_list:\n",
    "        parts = re.split(r'\\s*,\\s*|\\s+', entry)  # Split on spaces or commas\n",
    "        base_code = parts[0]  # Initialize base code\n",
    "        base_code_count = 0  # Tracks the number of expansions of current base code\n",
    "\n",
    "        # If list only contains one element, add it to the expanded list\n",
    "        if len(parts) == 1:\n",
    "            expanded_codes.append(parts[0])\n",
    "        \n",
    "        # Else iterate over the parts\n",
    "        for part in parts[1:]: # Parts always starts with the base code\n",
    "            # First, check for ranges with hyphens (e.g., 5/40-5/48)\n",
    "            if re.match(r'^\\d{1,2}/\\d{2,3}-\\d{1,2}/\\d{2,3}$', part):\n",
    "                if base_code:  # Only process if base_code exists\n",
    "                    start, end = part.split('-')\n",
    "                    expanded_codes.append(f\"{base_code} {start} - {base_code} {end}\")\n",
    "                    base_code_count += 1\n",
    "\n",
    "            # Check for full IPC codes with slashes (e.g., 5/00, 67/00)\n",
    "            elif re.match(r'^\\d{1,2}/\\d{2,3}$', part):\n",
    "                if base_code:  # Combine with base code\n",
    "                    expanded_codes.append(f\"{base_code} {part}\")\n",
    "                    base_code_count += 1\n",
    "\n",
    "            # Check if part might be a base code (e.g., A01, B02, H03F)\n",
    "            elif re.match(r'^[A-Z]{1,3}\\d{2}[A-Z]?', part):\n",
    "                # If base code exists and has not been expanded, it must be standalone\n",
    "                if base_code_count == 0:\n",
    "                    expanded_codes.append(f\"{base_code}\")\n",
    "                base_code = part\n",
    "                base_code_count = 0\n",
    "                # If part is last element in list, it must be standalone\n",
    "                if part == parts[-1]:\n",
    "                    expanded_codes.append(f\"{base_code}\")\n",
    "\n",
    "    return expanded_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and expand IPC codes\n",
    "expanded_ipc_list = expand_ipc_codes(ipc_combined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/thiesen/Documents/Projekt_EDV-TEK/ipc_valid_symbols_20240101/ipc_valid_symbols_20240101.html', 'r') as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Extract the IPC symbols\n",
    "ipc_symbols = [p.text for p in soup.find_all('p')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_ranges(expanded_ipc_list, ipc_symbols):\n",
    "    \"\"\"\n",
    "    Expands hyphenated ranges in IPC codes to individual entries (e.g., \"A23K 10/06-10\").\n",
    "    Keeps entries without a hyphen as-is and handles cases where some intermediate codes may be missing.\n",
    "\n",
    "    Parameters:\n",
    "    - expanded_cpc_list (iterable of str): IPC codes (potentially with ranges).\n",
    "    - cpc_symbols (list): Ordered list of all possible IPC codes.\n",
    "\n",
    "    Returns:\n",
    "    - list of str: IPC codes with all recognized ranges expanded.\n",
    "    \"\"\"\n",
    "    exploded_list = []\n",
    "    \n",
    "    for entry in expanded_ipc_list:\n",
    "        # Primary Pass: Expand entries with a slash-hyphen-suffix (e.g., \"A23K 10/06-10\")\n",
    "        slash_hyphen_match = re.match(r'^([A-Z0-9]+\\s+\\d+)/(\\d+)-(\\d+)$', entry)\n",
    "        if slash_hyphen_match:\n",
    "            prefix = slash_hyphen_match.group(1) + '/'  # e.g., \"A23K 10/\"\n",
    "            start_num = int(slash_hyphen_match.group(2))  # e.g., 06\n",
    "            end_num = int(slash_hyphen_match.group(3))    # e.g., 10\n",
    "            \n",
    "            # Generate all codes within the range\n",
    "            for num in range(start_num, end_num + 1):\n",
    "                new_num = f\"{num:02d}\"  # Ensure two digits\n",
    "                new_code = f\"{prefix}{new_num}\"\n",
    "                if new_code in ipc_symbols:\n",
    "                    exploded_list.append(new_code)\n",
    "            continue  # Move to the next entry after processing\n",
    "                \n",
    "        # Second Pass: Handle plain numeric ranges (e.g., \"F02M 39-71\")\n",
    "        numeric_range_match = re.match(r'^([A-Z0-9]+)\\s+(\\d+)-(\\d+)$', entry)\n",
    "        if numeric_range_match:\n",
    "            prefix = numeric_range_match.group(1)  # e.g., \"F02M\"\n",
    "            start_num = int(numeric_range_match.group(2))   # e.g., 39\n",
    "            end_num = int(numeric_range_match.group(3))     # e.g., 71\n",
    "            \n",
    "            for num in range(start_num, end_num + 1):\n",
    "                new_code = f\"{prefix} {num}\"\n",
    "                if new_code in ipc_symbols:\n",
    "                    exploded_list.append(new_code)\n",
    "            continue\n",
    "        \n",
    "        # Third Pass: Handle single numeric codes with slash (e.g., \"F02D 41\")\n",
    "        single_numeric_match = re.match(r'^([A-Z0-9]+)\\s+(\\d+)$', entry)\n",
    "        if single_numeric_match:\n",
    "            prefix = single_numeric_match.group(1)  # e.g., \"F02D\"\n",
    "            num = single_numeric_match.group(2)     # e.g., \"41\"\n",
    "            search_prefix = f\"{prefix} {num}/\"\n",
    "            \n",
    "            # Find all codes that start with the search_prefix\n",
    "            matching_codes = [s for s in ipc_symbols if s.startswith(search_prefix)]\n",
    "            if matching_codes:\n",
    "                exploded_list.extend(matching_codes)\n",
    "            else:\n",
    "                # If no expansions found, retain the original\n",
    "                exploded_list.append(entry)\n",
    "            continue\n",
    "        \n",
    "        # If none of the patterns match, just append the entry as-is\n",
    "        exploded_list.append(entry)\n",
    "    \n",
    "    return exploded_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_expanded_ipc_list = expand_ranges(expanded_ipc_list, ipc_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deduplicate the list\n",
    "range_expanded_ipc_list = list(set(range_expanded_ipc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(range_expanded_ipc_list), len(ipc_combined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_base_code(range_expanded_ipc_list, ipc_symbols):\n",
    "    expanded_list = []\n",
    "\n",
    "    # Define the regex pattern for letter-number-number or letter-number-number-letter\n",
    "    pattern = re.compile(r\"^[A-Z]\\d{2}[A-Z]?$\")\n",
    "\n",
    "    for entry in range_expanded_ipc_list:\n",
    "        # Check if the entry matches the pattern\n",
    "        if pattern.match(entry):\n",
    "            # Include all IPC symbols that start with the exact entry\n",
    "            matching_symbols = [symbol for symbol in ipc_symbols if symbol.startswith(entry)]\n",
    "            expanded_list.extend(matching_symbols)\n",
    "        else:\n",
    "            # Retain entries that do not match the pattern\n",
    "            expanded_list.append(entry)\n",
    "\n",
    "    return expanded_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand base codes in IPC codes\n",
    "final_expanded_ipc_list = expand_base_code(range_expanded_ipc_list, ipc_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deduplicate the list\n",
    "final_expanded_ipc_list = list(set(final_expanded_ipc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_expanded_ipc_list), len(range_expanded_ipc_list), len(ipc_combined_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IPC Postgres Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_ipc_symbols(ipc_list):\n",
    "    \"\"\"\n",
    "    Transform IPC symbols to ensure:\n",
    "    - The slash '/' is always at the 9th position.\n",
    "    - Spaces are padded dynamically between the first part and the main group.\n",
    "    \n",
    "    Args:\n",
    "        ipc_list (list): List of IPC symbols.\n",
    "    \n",
    "    Returns:\n",
    "        list: Formatted IPC symbols.\n",
    "    \"\"\"\n",
    "    transformed_list = []\n",
    "    \n",
    "    for ipc in ipc_list:\n",
    "        parts = ipc.split()  # Split on spaces\n",
    "        if len(parts) == 1:  # Short symbol (e.g., 'B61', 'A61K')\n",
    "            transformed_list.append(ipc)\n",
    "            continue\n",
    "        \n",
    "        first_part = parts[0]  # Section, IPC class, subclass\n",
    "        subgroup = parts[1]    # Main group and subgroup\n",
    "        \n",
    "        # Split subgroup into pre-slash and post-slash components\n",
    "        if '/' in subgroup:\n",
    "            before_slash, after_slash = subgroup.split('/')\n",
    "        else:\n",
    "            transformed_list.append(ipc)  # Skip if malformed\n",
    "            continue\n",
    "        \n",
    "        # Calculate the padding needed to align the slash to position 9\n",
    "        num_spaces = 8 - (len(first_part) + len(before_slash))\n",
    "        num_spaces = max(num_spaces, 1)  # Ensure at least 1 space\n",
    "        \n",
    "        # Combine the parts into the final formatted symbol\n",
    "        formatted_symbol = f\"{first_part}{' ' * num_spaces}{before_slash}/{after_slash}\"\n",
    "        transformed_list.append(formatted_symbol)\n",
    "    \n",
    "    return transformed_list\n",
    "\n",
    "# Transform IPC symbols\n",
    "transformed_ipc_list = transform_ipc_symbols(final_expanded_ipc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ipc_index = \"\"\"CREATE INDEX idx_ipc_class_symbol ON tls209_appln_ipc(ipc_class_symbol);\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ipc_green_inventory = \"\"\"\n",
    "    SELECT a.appln_id, a.ipc_class_symbol\n",
    "    FROM tls209_appln_ipc a\n",
    "    JOIN tls201_appln b ON a.appln_id = b.appln_id\n",
    "    WHERE a.ipc_class_symbol IN :ipc_classes\n",
    "      AND b.appln_auth IN ('EP', 'US')\n",
    "      AND b.granted = 'Y';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as connection:\n",
    "    # connection.execute(text(query_ipc_index))  # Only required once\n",
    "    df_ipc = pd.read_sql_query(\n",
    "        text(query_ipc_green_inventory),\n",
    "        connection,\n",
    "        params={\"ipc_classes\": tuple(transformed_ipc_list)},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_ipc['appln_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OECD Envtech (IPC and CPC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ipc_envtech = pd.read_csv('/home/thiesen/Documents/Projekt_EDV-TEK/OECD_envtech/expanded_cleaned_classification_oecd_envtech_ipc.csv', header=None, names=['ipc_class_symbol'])\n",
    "df_cpc_envtech = pd.read_csv('/home/thiesen/Documents/Projekt_EDV-TEK/OECD_envtech/expanded_cleaned_classification_oecd_envtech_cpc.csv', header=None, names=['cpc_class_symbol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_symbols(symbols_list):\n",
    "    \"\"\"\n",
    "    Transform IPC symbols to ensure:\n",
    "    - The slash '/' is always at the 9th position.\n",
    "    - Spaces are padded dynamically between the first part and the main group.\n",
    "    \n",
    "    Args:\n",
    "        ipc_list (list): List of IPC symbols or cpc_list (list): List of CPC symbols.\n",
    "    \n",
    "    Returns:\n",
    "        list: Formatted IPC and/or CPC symbols.\n",
    "    \"\"\"\n",
    "    transformed_list = []\n",
    "    \n",
    "    for symbol in symbols_list:\n",
    "        parts = symbol.split()  # Split on spaces\n",
    "        if len(parts) == 1:  # Short symbol (e.g., 'B61', 'A61K')\n",
    "            transformed_list.append(symbol)\n",
    "            continue\n",
    "        \n",
    "        first_part = parts[0]  # Section, IPC class, subclass\n",
    "        subgroup = parts[1]    # Main group and subgroup\n",
    "        \n",
    "        # Split subgroup into pre-slash and post-slash components\n",
    "        if '/' in subgroup:\n",
    "            before_slash, after_slash = subgroup.split('/')\n",
    "        else:\n",
    "            transformed_list.append(symbol)  # Skip if malformed\n",
    "            continue\n",
    "        \n",
    "        # Calculate the padding needed to align the slash to position 9\n",
    "        num_spaces = 8 - (len(first_part) + len(before_slash))\n",
    "        num_spaces = max(num_spaces, 1)  # Ensure at least 1 space\n",
    "        \n",
    "        # Combine the parts into the final formatted symbol\n",
    "        formatted_symbol = f\"{first_part}{' ' * num_spaces}{before_slash}/{after_slash}\"\n",
    "        transformed_list.append(formatted_symbol)\n",
    "    \n",
    "    return transformed_list\n",
    "\n",
    "# Transform IPC and CPC symbols\n",
    "transformed_ipc_envtech = transform_symbols(df_ipc_envtech['ipc_class_symbol'].tolist())\n",
    "transformed_cpc_envtech = transform_symbols(df_cpc_envtech['cpc_class_symbol'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ipc_envtech_index = \"\"\"CREATE INDEX idx_ipc_class_symbol ON tls209_appln_ipc(ipc_class_symbol);\"\"\"\n",
    "query_cpc_envtech_index = \"\"\"CREATE INDEX idx_cpc_class_symbol ON tls224_appln_cpc(cpc_class_symbol);\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ipc_envtech = \"\"\"\n",
    "    SELECT a.appln_id, a.ipc_class_symbol\n",
    "    FROM tls209_appln_ipc a\n",
    "    JOIN tls201_appln b ON a.appln_id = b.appln_id\n",
    "    WHERE a.ipc_class_symbol IN :ipc_classes\n",
    "      AND b.appln_auth IN ('EP', 'US')\n",
    "      AND b.granted = 'Y';\n",
    "\"\"\"\n",
    "\n",
    "query_cpc_envtech = \"\"\"\n",
    "    SELECT a.appln_id, a.cpc_class_symbol\n",
    "    FROM tls224_appln_cpc a\n",
    "    JOIN tls201_appln b ON a.appln_id = b.appln_id\n",
    "    WHERE a.cpc_class_symbol IN :cpc_classes\n",
    "      AND b.appln_auth IN ('EP', 'US')\n",
    "      AND b.granted = 'Y';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as connection:\n",
    "    # connection.execute(text(query_ipc_envtech_index))\n",
    "    # connection.execute(text(query_cpc_envtech_index))\n",
    "    df_ipc_envtech = pd.read_sql_query(\n",
    "        text(query_ipc_envtech),\n",
    "        connection,\n",
    "        params={\"ipc_classes\": tuple(transformed_ipc_envtech)},\n",
    "    )\n",
    "    df_cpc_envtech = pd.read_sql_query(\n",
    "        text(query_cpc_envtech),\n",
    "        connection,\n",
    "        params={\"cpc_classes\": tuple(transformed_cpc_envtech)},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_ipc_envtech['appln_id'].unique()), len(df_cpc_envtech['appln_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate CPC and IPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat([df_ipc, df_cpc], ignore_index=True)\n",
    "# df = pd.concat([df_ipc_envtech, df_cpc_envtech], ignore_index=True) # Only for OECD-Envtech\n",
    "df = pd.concat([df_ipc, df_cpc, df_ipc_envtech, df_cpc_envtech], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subsume Patents per appln_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df.groupby('appln_id').agg({\n",
    "    'ipc_class_symbol': lambda x: list(x),\n",
    "    'cpc_class_symbol': lambda x: list(x)\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped.to_csv('/mnt/hdd02/Projekt_EDV_TEK/edv_tek_all_cleantech_appln_ids.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = pd.read_csv('/mnt/hdd02/Projekt_EDV_TEK/edv_tek_all_cleantech_appln_ids.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Patent Fulltext Data for appln_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Temp Table with appln_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "appln_ids = df_grouped['appln_id'].tolist()\n",
    "\n",
    "# Create a temporary table and insert application IDs\n",
    "temp_table_query = \"\"\"\n",
    "    DROP TABLE IF EXISTS temp_appln_ids;\n",
    "    CREATE TEMP TABLE temp_appln_ids (appln_id TEXT);\n",
    "\"\"\"\n",
    "insert_query = text(\"INSERT INTO temp_appln_ids (appln_id) VALUES (:appln_id)\")\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(temp_table_query))\n",
    "    for id in appln_ids:\n",
    "        connection.execute(insert_query, {'appln_id': id})\n",
    "    connection.commit()\n",
    "\n",
    "    # Perform the join query to extract all valid publn_nr per appln_id\n",
    "    join_query = \"\"\"\n",
    "        SELECT t1.appln_id, t2.publn_auth, t2.publn_nr, t2.publn_date\n",
    "        FROM temp_appln_ids t1\n",
    "        JOIN (\n",
    "            SELECT appln_id, publn_auth, publn_nr, publn_date\n",
    "            FROM tls211_pat_publn\n",
    "        ) t2 ON t1.appln_id = t2.appln_id;\n",
    "    \"\"\"\n",
    "    result = connection.execute(text(join_query))\n",
    "    df_temp_publn = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "\n",
    "df_temp_publn['publn_nr'] = df_temp_publn['publn_nr'].astype(str)\n",
    "shortest_publn_nr_idx = df_temp_publn.groupby('appln_id')['publn_nr'].apply(lambda x: x.str.len().idxmin())\n",
    "df_shortest_publn = df_temp_publn.loc[shortest_publn_nr_idx]\n",
    "\n",
    "# Insert the filtered results back into the database\n",
    "temp_table_with_publn_query = \"\"\"\n",
    "    DROP TABLE IF EXISTS temp_appln_ids_with_publn;\n",
    "    CREATE TEMP TABLE temp_appln_ids_with_publn (appln_id TEXT, publn_auth TEXT, publn_nr TEXT, publn_date DATE);\n",
    "    CREATE INDEX temp_appln_ids_with_publn_index ON temp_appln_ids_with_publn(publn_nr, publn_auth);\n",
    "\"\"\"\n",
    "insert_filtered_query = text(\"INSERT INTO temp_appln_ids_with_publn (appln_id, publn_auth, publn_nr, publn_date) VALUES (:appln_id, :publn_auth, :publn_nr, :publn_date)\")\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(temp_table_with_publn_query))\n",
    "    for _, row in df_shortest_publn.iterrows():\n",
    "        connection.execute(insert_filtered_query, {'appln_id': row['appln_id'], 'publn_auth': row['publn_auth'], 'publn_nr': row['publn_nr'], 'publn_date': row['publn_date']})\n",
    "    connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Title and Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_title_abstr = \"\"\"\n",
    "    SELECT ids.appln_id, ids.publn_nr, ids.publn_auth, ids.publn_date, title.appln_title, abstract.appln_abstract\n",
    "    FROM temp_appln_ids_with_publn ids\n",
    "    JOIN tls202_appln_title title ON ids.appln_id = title.appln_id AND title.appln_title_lg = 'en'\n",
    "    JOIN tls203_appln_abstr abstract ON ids.appln_id = abstract.appln_id AND abstract.appln_abstract_lg = 'en'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as connection:\n",
    "    df_title_abstr = pd.read_sql_query(text(query_title_abstr), connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title_abstr.to_parquet('/mnt/hdd02/Projekt_EDV_TEK/edv_tek_all_cleantech_title_abstract.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract US Brf Summary (currently only Title, Abstract, Claims considered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as connection:\n",
    "    query_us_brf_summary = \"\"\"\n",
    "        SELECT t1.*, t2.*\n",
    "        FROM temp_appln_ids_with_publn t1\n",
    "        JOIN us_brf_summary t2 ON t1.publn_nr = t2.patent_id AND t1.publn_auth = t2.publn_auth;\n",
    "    \"\"\"\n",
    "    df_us_brf_summary = pd.read_sql(query_us_brf_summary, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_brf_summary = df_us_brf_summary.dropna(subset=['summary_text'])\n",
    "df_us_brf_summary['summary_text'] = df_us_brf_summary['summary_text'].apply(lambda x: re.sub(r'\\n', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_brf_summary = df_us_brf_summary.loc[:, ~df_us_brf_summary.columns.duplicated()]\n",
    "df_us_brf_summary.to_parquet('us_brf_summary.parquet', index=False) # Currently not used!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_brf_summary = pd.read_parquet('us_brf_summary.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract US Claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as connection:\n",
    "    query_us_claims = \"\"\"\n",
    "        SELECT t1.*, t2.*\n",
    "        FROM temp_appln_ids_with_publn t1\n",
    "        JOIN us_claims t2 ON t1.publn_nr = t2.patent_id AND t1.publn_auth = t2.publn_auth;\n",
    "    \"\"\"\n",
    "    df_us_claims = pd.read_sql(query_us_claims, connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_claims = df_us_claims.dropna(subset=['claim_text'])\n",
    "df_us_claims.sort_values(by=['patent_id', 'claim_sequence'], inplace=True)\n",
    "df_us_claims_grouped = df_us_claims.groupby('appln_id').agg({\n",
    "    'patent_id': 'first',\n",
    "    'claim_text': list\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row):\n",
    "    claim_fulltext = ' '.join(re.sub(r'^\\d+\\.\\s', ' ', text) for text in row['claim_text'])\n",
    "    return pd.Series({'claim_fulltext': claim_fulltext})\n",
    "df_us_claims_grouped['claim_fulltext'] = df_us_claims_grouped.apply(process_row, axis=1)\n",
    "df_us_claims_grouped.drop('claim_text', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_claims_grouped.to_parquet('/mnt/hdd02/Projekt_EDV_TEK/edv_tek_us_claims.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_claims_grouped = pd.read_parquet('/mnt/hdd02/Projekt_EDV_TEK/edv_tek_us_claims.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract US Description (currently only Title, Abstract, Claims considered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as connection:    \n",
    "    query_us_description = \"\"\"\n",
    "        SELECT t1.*, t2.*\n",
    "        FROM temp_appln_ids_with_publn t1\n",
    "        JOIN us_description t2 ON t1.publn_nr = t2.patent_id AND t1.publn_auth = t2.publn_auth;\n",
    "    \"\"\"\n",
    "    df_us_description = pd.read_sql(query_us_description, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_description = df_us_description.dropna(subset=['description_text'])\n",
    "df_us_description['description_text'] = df_us_description['description_text'].apply(lambda x: re.sub(r'\\n', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_description.to_csv('/mnt/hdd02/cleantech_patents_ipc_cpc/Extract_all_Cleantech_ipc_cpc/us_description.csv', index=False) # Currently not used!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract EP Fulltext (Title, Abstract, Brf Summary, Claims, Description) - (currently only Title, Abstract, Claims considered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as connection:    \n",
    "    ## Extract all fulltext data\n",
    "    # query_ep_fulltext_data = \"\"\" \n",
    "    #     SELECT t1.*, t2.*\n",
    "    #     FROM temp_appln_ids_with_publn t1 \n",
    "    #     JOIN ep_fulltext_data t2 \n",
    "    #     ON t1.publn_nr = t2.epo_publn_nr\n",
    "    #     AND t1.publn_auth = t2.publn_auth\n",
    "    #     WHERE t2.appln_lng = 'en';\n",
    "    # \"\"\"\n",
    "    ## Only extract CLAIM fulltext data\n",
    "    query_ep_fulltext_data = \"\"\"\n",
    "        SELECT t1.*, t2.*\n",
    "        FROM temp_appln_ids_with_publn t1 \n",
    "        JOIN ep_fulltext_data t2 \n",
    "            ON t1.publn_nr = t2.epo_publn_nr\n",
    "            AND t1.publn_auth = t2.publn_auth\n",
    "        WHERE t2.appln_lng = 'en'\n",
    "          AND t2.appln_comp = 'CLAIM';\n",
    "    \"\"\"\n",
    "    df_ep_fulltext_data = pd.read_sql(query_ep_fulltext_data, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = {'B9': 11, 'B8': 10, 'B3': 9, 'B2': 8, 'B1': 7, 'A9': 6, 'A8': 5, 'A4': 4, 'A3': 3, 'A2': 2, 'A1': 1}\n",
    "df_ep_fulltext_data['order'] = df_ep_fulltext_data['appln_kind'].map(order)\n",
    "df_ep_fulltext_data.drop(['epo_publn_nr', 'appln_auth', 'appln_date', 'appln_lng', 'appln_text_type'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ep_fulltext_data_description = df_ep_fulltext_data[df_ep_fulltext_data['appln_comp'] == 'DESCR']\n",
    "df_ep_fulltext_data_claims = df_ep_fulltext_data[df_ep_fulltext_data['appln_comp'] == 'CLAIM']\n",
    "# df_ep_fulltext_data_amend = df_ep_fulltext_data[df_ep_fulltext_data['appln_comp'] == 'AMEND']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ep_fulltext_data_description = df_ep_fulltext_data_description.sort_values(by=['publn_nr', 'order'])\n",
    "df_ep_fulltext_data_claims = df_ep_fulltext_data_claims.sort_values(by=['publn_nr', 'order'])\n",
    "\n",
    "# df_ep_fulltext_data_description = df_ep_fulltext_data_description.groupby('publn_nr').first().reset_index()\n",
    "df_ep_fulltext_data_claims = df_ep_fulltext_data_claims.groupby('publn_nr').first().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html(text):\n",
    "    cleaned_text = re.sub(r'<!--.*?-->', ' ', text)\n",
    "    soup = BeautifulSoup(cleaned_text, 'html.parser')\n",
    "    cleaned_text = soup.get_text(separator=' ')\n",
    "    return cleaned_text\n",
    "def clean_claim_text(claim_text):\n",
    "    # Remove all instances of <!--(.*?)-->\n",
    "    claim_text = re.sub(r'<!--.*?-->', ' ', claim_text)\n",
    "\n",
    "    # Parse the claim_text as XML using BeautifulSoup\n",
    "    soup = BeautifulSoup(claim_text, 'html.parser')\n",
    "    \n",
    "    # Extract all text from <claim-text> tags\n",
    "    cleaned_texts = [elem.get_text() for elem in soup.find_all('claim-text') if elem.get_text()]\n",
    "\n",
    "    # Join the cleaned texts\n",
    "    cleaned_text = ' '.join(cleaned_texts)\n",
    "    \n",
    "    return cleaned_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ep_fulltext_data_description['appln_text'] = df_ep_fulltext_data_description['appln_text'].apply(clean_html)\n",
    "df_ep_fulltext_data_claims['appln_text'] = df_ep_fulltext_data_claims['appln_text'].apply(clean_claim_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ep_fulltext_data_description.to_csv('oecd_envtech_ipc_cpc_ep_description.csv', index=False)\n",
    "# df_ep_fulltext_data_claims.to_csv('oecd_envtech_ipc_cpc_ep_claims.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ep_fulltext_data_description.to_parquet('ep_description.parquet', index=False)\n",
    "df_ep_fulltext_data_claims = df_ep_fulltext_data_claims.loc[:, ~df_ep_fulltext_data_claims.columns.duplicated()]\n",
    "df_ep_fulltext_data_claims.to_parquet('/mnt/hdd02/Projekt_EDV_TEK/edv_tek_ep_claims.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ep_fulltext_data_claims = pd.read_parquet('/mnt/hdd02/Projekt_EDV_TEK/edv_tek_ep_claims.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build one common dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title_abstr = pd.read_parquet('/mnt/hdd02/Projekt_EDV_TEK/edv_tek_all_cleantech_title_abstract.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title_abstr.rename(columns={'publn_nr': 'patent_id', 'appln_title': 'title', 'appln_abstract': 'abstract'}, inplace=True)\n",
    "# Keep publn_date and publn_auth columns as they are\n",
    "# df_us_brf_summary.rename(columns={'summary_text': 'brf_summary'}, inplace=True)\n",
    "# df_us_brf_summary.drop(['publn_auth', 'publn_nr'], axis=1, inplace=True)\n",
    "# df_us_description.rename(columns={'description_text': 'description'}, inplace=True)\n",
    "# df_us_description.drop(['publn_auth', 'publn_nr', 'description_length'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_patents = pd.DataFrame()\n",
    "df_cleantech_patents = pd.concat([df_cleantech_patents, df_title_abstr])\n",
    "# df_cleantech_patents = df_cleantech_patents.merge(df_us_brf_summary, on=['appln_id', 'patent_id'], how='outer').drop_duplicates(subset=['appln_id', 'patent_id']).reset_index(drop=True)\n",
    "# df_cleantech_patents = df_cleantech_patents.merge(df_us_description, on=['appln_id', 'patent_id'], how='outer').drop_duplicates(subset=['appln_id', 'patent_id']).reset_index(drop=True)\n",
    "df_cleantech_patents = df_cleantech_patents.merge(df_us_claims_grouped, on=['appln_id', 'patent_id'], how='outer').drop_duplicates(subset=['appln_id', 'patent_id']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appln_id</th>\n",
       "      <th>patent_id</th>\n",
       "      <th>publn_auth</th>\n",
       "      <th>publn_date</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>claim_fulltext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1707773</th>\n",
       "      <td>53485948</td>\n",
       "      <td>6141698</td>\n",
       "      <td>US</td>\n",
       "      <td>2000-10-31</td>\n",
       "      <td>Method and system for injecting new code into ...</td>\n",
       "      <td>A method and system for modifying the behavior...</td>\n",
       "      <td>A method in a computer system for modifying a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080270</th>\n",
       "      <td>490949333</td>\n",
       "      <td>10269966</td>\n",
       "      <td>US</td>\n",
       "      <td>2019-04-23</td>\n",
       "      <td>Semiconductor device including a fin structure</td>\n",
       "      <td>A semiconductor device including a Fin FET dev...</td>\n",
       "      <td>A semiconductor device, comprising: a Fin FET...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001223</th>\n",
       "      <td>485618147</td>\n",
       "      <td>10357867</td>\n",
       "      <td>US</td>\n",
       "      <td>2019-07-23</td>\n",
       "      <td>Polishing system</td>\n",
       "      <td>A polishing system includes a wafer support th...</td>\n",
       "      <td>A polishing system comprising: a wafer suppor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665081</th>\n",
       "      <td>532169691</td>\n",
       "      <td>10669720</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-06-02</td>\n",
       "      <td>Stackable closure strip</td>\n",
       "      <td>Closure strip devices, systems, kits, assembli...</td>\n",
       "      <td>A closure strip for a building having a metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525111</th>\n",
       "      <td>52314141</td>\n",
       "      <td>7029957</td>\n",
       "      <td>US</td>\n",
       "      <td>2006-04-18</td>\n",
       "      <td>Method of manufacturing semiconductor device h...</td>\n",
       "      <td>A method of manufacturing a semiconductor devi...</td>\n",
       "      <td>A method of manufacturing a semiconductor dev...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          appln_id patent_id publn_auth  publn_date  \\\n",
       "1707773   53485948   6141698         US  2000-10-31   \n",
       "1080270  490949333  10269966         US  2019-04-23   \n",
       "1001223  485618147  10357867         US  2019-07-23   \n",
       "1665081  532169691  10669720         US  2020-06-02   \n",
       "1525111   52314141   7029957         US  2006-04-18   \n",
       "\n",
       "                                                     title  \\\n",
       "1707773  Method and system for injecting new code into ...   \n",
       "1080270     Semiconductor device including a fin structure   \n",
       "1001223                                   Polishing system   \n",
       "1665081                            Stackable closure strip   \n",
       "1525111  Method of manufacturing semiconductor device h...   \n",
       "\n",
       "                                                  abstract  \\\n",
       "1707773  A method and system for modifying the behavior...   \n",
       "1080270  A semiconductor device including a Fin FET dev...   \n",
       "1001223  A polishing system includes a wafer support th...   \n",
       "1665081  Closure strip devices, systems, kits, assembli...   \n",
       "1525111  A method of manufacturing a semiconductor devi...   \n",
       "\n",
       "                                            claim_fulltext  \n",
       "1707773   A method in a computer system for modifying a...  \n",
       "1080270   A semiconductor device, comprising: a Fin FET...  \n",
       "1001223   A polishing system comprising: a wafer suppor...  \n",
       "1665081   A closure strip for a building having a metal...  \n",
       "1525111   A method of manufacturing a semiconductor dev...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleantech_patents.sample(5) ### UNTIL HERE!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ep_fulltext_data_description.rename(columns={'publn_nr': 'patent_id', 'appln_text': 'description'}, inplace=True)\n",
    "# df_ep_fulltext_data_description.drop(['publn_auth', 'appln_kind', 'appln_comp', 'order'], axis=1, inplace=True)\n",
    "\n",
    "df_ep_fulltext_data_claims.rename(columns={'publn_nr': 'patent_id', 'appln_text': 'claim_fulltext'}, inplace=True)\n",
    "df_ep_fulltext_data_claims.drop(['publn_auth', 'appln_kind', 'appln_comp', 'order'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ep_fulltext_data_description['patent_id'] = df_ep_fulltext_data_description['patent_id'].astype(str)\n",
    "df_ep_fulltext_data_claims['patent_id'] = df_ep_fulltext_data_claims['patent_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cleantech_patents = df_cleantech_patents.merge(df_ep_fulltext_data_description, on=['appln_id', 'patent_id'], how='outer').drop_duplicates(subset=['appln_id', 'patent_id']).reset_index(drop=True)\n",
    "df_cleantech_patents = df_cleantech_patents.merge(df_ep_fulltext_data_claims, on=['appln_id', 'patent_id'], how='outer').drop_duplicates(subset=['appln_id', 'patent_id']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cleantech_patents['description'] = df_cleantech_patents['description_x'].fillna(df_cleantech_patents['description_y'])\n",
    "df_cleantech_patents['claim_fulltext'] = df_cleantech_patents['claim_fulltext_x'].fillna(df_cleantech_patents['claim_fulltext_y'])\n",
    "# df_cleantech_patents.drop(['description_x', 'description_y', 'claim_fulltext_x', 'claim_fulltext_y'], axis=1, inplace=True)\n",
    "df_cleantech_patents.drop(['claim_fulltext_x', 'claim_fulltext_y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where either title, abstract or claim_fulltext is NaN\n",
    "df_cleantech_patents = df_cleantech_patents.dropna(subset=['title', 'abstract', 'claim_fulltext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_patents = df_cleantech_patents.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to parquet\n",
    "df_cleantech_patents.to_parquet('/mnt/hdd02/Projekt_EDV_TEK/edv_tek_cleantech_patents_all.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Dataframe containing Title, Abstract, Claims with Dataframe containing CPC and IPC codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_patents = pd.read_parquet('/mnt/hdd02/Projekt_EDV_TEK/edv_tek_cleantech_patents_all.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = pd.read_csv('/mnt/hdd02/Projekt_EDV_TEK/edv_tek_all_cleantech_appln_ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_patents['appln_id'] = df_cleantech_patents['appln_id'].astype(str)\n",
    "df_grouped['appln_id'] = df_grouped['appln_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_patents_cpc_ipc = pd.merge(df_cleantech_patents, df_grouped, on=['appln_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_and_clean(sym_str):\n",
    "    \"\"\"\n",
    "    - If already a list/array, return as‐is\n",
    "    - If a string like \"[nan, 'A01B 1/00', nan]\", replace nan→None,\n",
    "      ast.literal_eval(), then map None→np.nan.\n",
    "    \"\"\"\n",
    "    if not isinstance(sym_str, str):\n",
    "        return sym_str\n",
    "    # 1) turn unquoted nan into Python None\n",
    "    tmp = sym_str.replace('nan', 'None')\n",
    "    # 2) safely parse literal\n",
    "    try:\n",
    "        lst = ast.literal_eval(tmp)\n",
    "    except Exception:\n",
    "        return []  # or return [np.nan]\n",
    "    # 3) map None→np.nan\n",
    "    return [x if x is not None else np.nan for x in lst]\n",
    "\n",
    "def drop_extra_nan(lst):\n",
    "    \"\"\"\n",
    "    - Remove all np.nan from the list\n",
    "    - If list ends up empty, return [np.nan]\n",
    "    \"\"\"\n",
    "    cleaned = [x for x in lst if pd.notna(x)]\n",
    "    return cleaned if cleaned else [np.nan]\n",
    "\n",
    "# Apply to both columns:\n",
    "df = df_cleantech_patents_cpc_ipc\n",
    "\n",
    "# 1) parse string→list, unify nan\n",
    "df['ipc_class_symbol'] = (df['ipc_class_symbol']\n",
    "    .apply(parse_and_clean)\n",
    "    .apply(drop_extra_nan)\n",
    ")\n",
    "\n",
    "df['cpc_class_symbol'] = (df['cpc_class_symbol']\n",
    "    .apply(parse_and_clean)\n",
    "    .apply(drop_extra_nan)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_patents_cpc_ipc.to_parquet('/mnt/hdd02/Projekt_EDV_TEK/edv_tek_cleantech_patents_title_abstract_date_cpc_ipc.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appln_id</th>\n",
       "      <th>patent_id</th>\n",
       "      <th>publn_auth</th>\n",
       "      <th>publn_date</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>claim_fulltext</th>\n",
       "      <th>ipc_class_symbol</th>\n",
       "      <th>cpc_class_symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>486846</th>\n",
       "      <td>422594458</td>\n",
       "      <td>3050140</td>\n",
       "      <td>EP</td>\n",
       "      <td>2019-03-20</td>\n",
       "      <td>METHOD FOR PRODUCING AN ELECTRODE FOR A LITHIU...</td>\n",
       "      <td>The invention relates to a method for producin...</td>\n",
       "      <td>A method of manufacturing a secondary battery ...</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[Y02E  60/10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683269</th>\n",
       "      <td>46198188</td>\n",
       "      <td>7282988</td>\n",
       "      <td>US</td>\n",
       "      <td>2007-10-16</td>\n",
       "      <td>Bandgap reference circuit</td>\n",
       "      <td>A bandgap reference circuit is proposed. To re...</td>\n",
       "      <td>A bandgap reference circuit, comprising: a fi...</td>\n",
       "      <td>[H01L  23/58]</td>\n",
       "      <td>[nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127419</th>\n",
       "      <td>315438118</td>\n",
       "      <td>7985830</td>\n",
       "      <td>US</td>\n",
       "      <td>2011-07-26</td>\n",
       "      <td>Method for making nitrogen aromatic oligomers ...</td>\n",
       "      <td>Methods for synthesizing dimeric or polymeric ...</td>\n",
       "      <td>A method for polymerizing pyridine, comprisin...</td>\n",
       "      <td>[B01J  23/42, B01J  23/44]</td>\n",
       "      <td>[nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614782</th>\n",
       "      <td>53744471</td>\n",
       "      <td>7391292</td>\n",
       "      <td>US</td>\n",
       "      <td>2008-06-24</td>\n",
       "      <td>Inductors having interconnect and inductor por...</td>\n",
       "      <td>An on-chip inductor includes a main inductor p...</td>\n",
       "      <td>An on-chip inductor comprising: a main induct...</td>\n",
       "      <td>[H01L  21/02, H01L  21/822, H01L  23/522, H01L...</td>\n",
       "      <td>[nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554779</th>\n",
       "      <td>53382566</td>\n",
       "      <td>6684119</td>\n",
       "      <td>US</td>\n",
       "      <td>2004-01-27</td>\n",
       "      <td>Method of providing dynamic production materia...</td>\n",
       "      <td>A method of providing dynamic production mater...</td>\n",
       "      <td>A method of providing dynamic production mate...</td>\n",
       "      <td>[G06Q  10/00, G06Q  10/08]</td>\n",
       "      <td>[nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535928</th>\n",
       "      <td>439819877</td>\n",
       "      <td>10084196</td>\n",
       "      <td>US</td>\n",
       "      <td>2018-09-25</td>\n",
       "      <td>System and method for controlling fuel cell mo...</td>\n",
       "      <td>A fuel cell module has a hydrogen recirculatio...</td>\n",
       "      <td>A process for operating a fuel cell stack com...</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[Y02E  60/50]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152405</th>\n",
       "      <td>50567331</td>\n",
       "      <td>6946264</td>\n",
       "      <td>US</td>\n",
       "      <td>2005-09-20</td>\n",
       "      <td>Metalloproteinase inhibitor</td>\n",
       "      <td>A novel metalloproteinase inhibitor, analogs t...</td>\n",
       "      <td>An isolated DNA encoding a polypeptide produc...</td>\n",
       "      <td>[C12N   1/21, C12N   5/10]</td>\n",
       "      <td>[nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641404</th>\n",
       "      <td>538871987</td>\n",
       "      <td>11453682</td>\n",
       "      <td>US</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>Condensed-cyclic compound and organic light-em...</td>\n",
       "      <td>A condensed-cyclic compound represented by For...</td>\n",
       "      <td>A condensed-cyclic compound represented by an...</td>\n",
       "      <td>[H01L  51/50]</td>\n",
       "      <td>[nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523353</th>\n",
       "      <td>531788124</td>\n",
       "      <td>11101648</td>\n",
       "      <td>US</td>\n",
       "      <td>2021-08-24</td>\n",
       "      <td>Power supply system</td>\n",
       "      <td>A power supply system includes a main line, a ...</td>\n",
       "      <td>A power supply system comprising: a main line...</td>\n",
       "      <td>[H02J   1/10, H02J   7/00]</td>\n",
       "      <td>[Y02T  10/70]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451542</th>\n",
       "      <td>527004670</td>\n",
       "      <td>11293853</td>\n",
       "      <td>US</td>\n",
       "      <td>2022-04-05</td>\n",
       "      <td>System and method for measuring vibrational sp...</td>\n",
       "      <td>Disclosed are systems and methods for measurin...</td>\n",
       "      <td>A system for measuring vibrational spectra of...</td>\n",
       "      <td>[G01R  23/02, G01R  23/16]</td>\n",
       "      <td>[nan]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          appln_id patent_id publn_auth  publn_date  \\\n",
       "486846   422594458   3050140         EP  2019-03-20   \n",
       "683269    46198188   7282988         US  2007-10-16   \n",
       "127419   315438118   7985830         US  2011-07-26   \n",
       "1614782   53744471   7391292         US  2008-06-24   \n",
       "1554779   53382566   6684119         US  2004-01-27   \n",
       "535928   439819877  10084196         US  2018-09-25   \n",
       "1152405   50567331   6946264         US  2005-09-20   \n",
       "1641404  538871987  11453682         US  2022-09-27   \n",
       "1523353  531788124  11101648         US  2021-08-24   \n",
       "1451542  527004670  11293853         US  2022-04-05   \n",
       "\n",
       "                                                     title  \\\n",
       "486846   METHOD FOR PRODUCING AN ELECTRODE FOR A LITHIU...   \n",
       "683269                           Bandgap reference circuit   \n",
       "127419   Method for making nitrogen aromatic oligomers ...   \n",
       "1614782  Inductors having interconnect and inductor por...   \n",
       "1554779  Method of providing dynamic production materia...   \n",
       "535928   System and method for controlling fuel cell mo...   \n",
       "1152405                        Metalloproteinase inhibitor   \n",
       "1641404  Condensed-cyclic compound and organic light-em...   \n",
       "1523353                                Power supply system   \n",
       "1451542  System and method for measuring vibrational sp...   \n",
       "\n",
       "                                                  abstract  \\\n",
       "486846   The invention relates to a method for producin...   \n",
       "683269   A bandgap reference circuit is proposed. To re...   \n",
       "127419   Methods for synthesizing dimeric or polymeric ...   \n",
       "1614782  An on-chip inductor includes a main inductor p...   \n",
       "1554779  A method of providing dynamic production mater...   \n",
       "535928   A fuel cell module has a hydrogen recirculatio...   \n",
       "1152405  A novel metalloproteinase inhibitor, analogs t...   \n",
       "1641404  A condensed-cyclic compound represented by For...   \n",
       "1523353  A power supply system includes a main line, a ...   \n",
       "1451542  Disclosed are systems and methods for measurin...   \n",
       "\n",
       "                                            claim_fulltext  \\\n",
       "486846   A method of manufacturing a secondary battery ...   \n",
       "683269    A bandgap reference circuit, comprising: a fi...   \n",
       "127419    A method for polymerizing pyridine, comprisin...   \n",
       "1614782   An on-chip inductor comprising: a main induct...   \n",
       "1554779   A method of providing dynamic production mate...   \n",
       "535928    A process for operating a fuel cell stack com...   \n",
       "1152405   An isolated DNA encoding a polypeptide produc...   \n",
       "1641404   A condensed-cyclic compound represented by an...   \n",
       "1523353   A power supply system comprising: a main line...   \n",
       "1451542   A system for measuring vibrational spectra of...   \n",
       "\n",
       "                                          ipc_class_symbol cpc_class_symbol  \n",
       "486846                                               [nan]    [Y02E  60/10]  \n",
       "683269                                       [H01L  23/58]            [nan]  \n",
       "127419                          [B01J  23/42, B01J  23/44]            [nan]  \n",
       "1614782  [H01L  21/02, H01L  21/822, H01L  23/522, H01L...            [nan]  \n",
       "1554779                         [G06Q  10/00, G06Q  10/08]            [nan]  \n",
       "535928                                               [nan]    [Y02E  60/50]  \n",
       "1152405                         [C12N   1/21, C12N   5/10]            [nan]  \n",
       "1641404                                      [H01L  51/50]            [nan]  \n",
       "1523353                         [H02J   1/10, H02J   7/00]    [Y02T  10/70]  \n",
       "1451542                         [G01R  23/02, G01R  23/16]            [nan]  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleantech_patents_cpc_ipc.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_patents_citations = pd.read_csv('/mnt/hdd02/Projekt_EDV_TEK/edv_tek_all_cleantech_patstat_citations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the number of pat_appln_id in df_cleantech_patents_citations that are in df_cleantech_patents_cpc_ipc column appln_id\n",
    "df_cleantech_patents_citations['pat_appln_id'] = df_cleantech_patents_citations['pat_appln_id'].astype(str)\n",
    "df_cleantech_patents_citations['cited_pat_appln_id'] = df_cleantech_patents_citations['cited_pat_appln_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of pat_appln_id in df_cleantech_patents_citations that are in df_cleantech_patents_cpc_ipc column appln_id\n",
    "print(\"Number of pat_appln_id in df_cleantech_patents_citations that are in df_cleantech_patents_cpc_ipc column appln_id:\")\n",
    "print(len(df_cleantech_patents_citations[df_cleantech_patents_citations['pat_appln_id'].isin(df_cleantech_patents_cpc_ipc['appln_id'])]))\n",
    "print(\"Number of pat_appln_id in df_cleantech_patents_citations that are NOT in df_cleantech_patents_cpc_ipc column appln_id:\")\n",
    "print(len(df_cleantech_patents_citations[~df_cleantech_patents_citations['pat_appln_id'].isin(df_cleantech_patents_cpc_ipc['appln_id'])]))\n",
    "print(\"Number of cited_pat_appln_id in df_cleantech_patents_citations that are in df_cleantech_patents_cpc_ipc column appln_id:\")\n",
    "print(len(df_cleantech_patents_citations[df_cleantech_patents_citations['cited_pat_appln_id'].isin(df_cleantech_patents_cpc_ipc['appln_id'])]))\n",
    "print(\"Number of cited_pat_appln_id in df_cleantech_patents_citations that are NOT in df_cleantech_patents_cpc_ipc column appln_id:\")\n",
    "print(len(df_cleantech_patents_citations[~df_cleantech_patents_citations['cited_pat_appln_id'].isin(df_cleantech_patents_cpc_ipc['appln_id'])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of columns where pat_appln_id is not in df_cleantech_patents_cpc_ipc column appln_id\n",
    "df_cleantech_patents_citations = df_cleantech_patents_citations[df_cleantech_patents_citations['pat_appln_id'].isin(df_cleantech_patents_cpc_ipc['appln_id'])]\n",
    "df_cleantech_patents_citations = df_cleantech_patents_citations[df_cleantech_patents_citations['cited_pat_appln_id'].isin(df_cleantech_patents_cpc_ipc['appln_id'])]\n",
    "df_cleantech_patents_citations = df_cleantech_patents_citations.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_patents_citations.to_csv('/mnt/hdd02/Projekt_EDV_TEK/edv_tek_all_cleantech_patstat_citations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_patents_citations.to_parquet('/mnt/hdd02/Projekt_EDV_TEK/edv_tek_all_cleantech_patstat_citations.parquet', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edv_tek",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
