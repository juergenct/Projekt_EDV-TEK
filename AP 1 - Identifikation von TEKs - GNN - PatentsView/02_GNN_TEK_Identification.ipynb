{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Construct new dataset where different labels types are also well connected**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /home/thiesen/.cache/torch/sentence_transformers/distilbert_distilbert-base-uncased. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import h5py\n",
    "import os.path as osp\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torch_geometric.data import HeteroData, Dataset, Data\n",
    "from torch_geometric.nn import GCNConv, HeteroConv, SAGEConv, GATConv, MessagePassing\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.explain import Explainer, GNNExplainer\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# stop_words = nltk.corpus.stopwords.words('english')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = 'distilbert/distilbert-base-uncased'\n",
    "model = SentenceTransformer(model_name).to(device)\n",
    "# model = SentenceTransformer('anferico/bert-for-patents').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sources** (Also for tomorrow)\n",
    "- https://pytorch-geometric.readthedocs.io/en/latest/tutorial/heterogeneous.html\n",
    "- https://pytorch-geometric.readthedocs.io/en/latest/tutorial/create_gnn.html\n",
    "- https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.HeteroConv.html#torch_geometric.nn.conv.HeteroConv\n",
    "- https://pytorch-geometric.readthedocs.io/en/latest/cheatsheet/gnn_cheatsheet.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_patent = pd.read_csv('/mnt/hdd01/patentsview/Raw files/Raw zip files/g_patent.tsv.zip', sep='\\t', compression='zip', usecols=['patent_id', 'patent_title', 'patent_abstract'], low_memory=False)\n",
    "g_cpc = pd.read_csv('/mnt/hdd01/patentsview/Raw files/Raw zip files/g_cpc_current.tsv.zip', sep='\\t', compression='zip', usecols=['patent_id', 'cpc_class'], low_memory=False)\n",
    "g_patent = g_patent.astype(str)\n",
    "g_cpc = g_cpc.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_patent_cpc = pd.merge(g_patent, g_cpc, on='patent_id')\n",
    "g_patent_cpc = g_patent_cpc.groupby('patent_id').agg({\n",
    "    'cpc_class': list,\n",
    "    'patent_title': 'first',\n",
    "    'patent_abstract': 'first'\n",
    "}).reset_index().rename(columns={'cpc_class': 'cpc_groups'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_patent_cleantech = g_patent_cpc[g_patent_cpc['cpc_groups'].apply(lambda x: 'Y02' in x)]\n",
    "# g_patent_non_cleantech = g_patent_cpc.sample(n=len(g_patent_cleantech), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_patent_citation = pd.read_csv('/mnt/hdd01/patentsview/Raw files/Raw zip files/g_us_patent_citation.tsv.zip', sep='\\t', compression='zip', usecols=['patent_id', 'citation_patent_id'], low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_patent_id_in_cleantech = g_patent_citation['patent_id'].isin(set(g_patent_cleantech['patent_id']))\n",
    "is_citation_id_in_cleantech = g_patent_citation['citation_patent_id'].isin(set(g_patent_cleantech['patent_id']))\n",
    "\n",
    "g_patent_citation_non_cleantech = g_patent_citation[is_patent_id_in_cleantech | is_citation_id_in_cleantech]\n",
    "\n",
    "not_patent_id_in_cleantech = ~is_patent_id_in_cleantech\n",
    "not_citation_id_in_cleantech = ~is_citation_id_in_cleantech\n",
    "patent_id_counts = g_patent_citation_non_cleantech.loc[not_patent_id_in_cleantech, 'patent_id'].value_counts()\n",
    "citation_patent_id_counts = g_patent_citation_non_cleantech.loc[not_citation_id_in_cleantech, 'citation_patent_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = min(len(g_patent_cleantech) // 2 + 100000, len(patent_id_counts), len(citation_patent_id_counts))\n",
    "top_patent_id_counts = patent_id_counts.head(n)\n",
    "top_citation_patent_id_counts = citation_patent_id_counts.head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        patent_id                      cpc_groups  \\\n",
      "5610296   8123546                           [H01]   \n",
      "2335129   4827887       [F02, F02, F02, F02, F02]   \n",
      "7320789   9849578  [H02, B25, B23, B23, Y10, B25]   \n",
      "2797642   5292511            [C12, A23, C12, C12]   \n",
      "1653626   4145281                           [B01]   \n",
      "\n",
      "                                              patent_title  \\\n",
      "5610296             Connector for large power transmission   \n",
      "2335129  Adaptive charge mixture control system for int...   \n",
      "7320789          Conductive boot for power tool protection   \n",
      "2797642  Process for manufacturing a health-supplementa...   \n",
      "1653626                         Water purification process   \n",
      "\n",
      "                                           patent_abstract  \n",
      "5610296  A connector includes a male terminal housing w...  \n",
      "2335129  An adaptive charge mixture control for an inte...  \n",
      "7320789  Apparatus for high voltage power line maintena...  \n",
      "2797642   A process for manufacturing a health-suppleme...  \n",
      "1653626   Process for the removal of chromium and zinc ...  \n"
     ]
    }
   ],
   "source": [
    "g_patent_non_cleantech = pd.concat([\n",
    "    g_patent_cpc.loc[g_patent_cpc['patent_id'].isin(top_patent_id_counts.index)],\n",
    "    g_patent_cpc.loc[g_patent_cpc['patent_id'].isin(top_citation_patent_id_counts.index)]\n",
    "]).drop_duplicates(subset='patent_id').sample(n=len(g_patent_cleantech), random_state=42)\n",
    "\n",
    "print(g_patent_non_cleantech.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # text = text.lower()\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text) # remove urls\n",
    "    text = re.sub(r'\\S+@\\S+', '', text) # remove emails\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text) # remove non-alphabets\n",
    "    text = re.sub(r'\\s+', ' ', text).strip() # remove multiple spaces\n",
    "    # text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 515783/515783 [00:04<00:00, 124440.51it/s]\n",
      "100%|██████████| 515783/515783 [00:26<00:00, 19661.59it/s]\n",
      "100%|██████████| 515783/515783 [00:03<00:00, 130574.08it/s]\n",
      "100%|██████████| 515783/515783 [00:26<00:00, 19165.96it/s]\n"
     ]
    }
   ],
   "source": [
    "g_patent_cleantech.loc[:, 'patent_title'] = g_patent_cleantech['patent_title'].progress_apply(preprocess_text)\n",
    "g_patent_cleantech.loc[:, 'patent_abstract'] = g_patent_cleantech['patent_abstract'].progress_apply(preprocess_text)\n",
    "g_patent_non_cleantech.loc[:, 'patent_title'] = g_patent_non_cleantech['patent_title'].progress_apply(preprocess_text)\n",
    "g_patent_non_cleantech.loc[:, 'patent_abstract'] = g_patent_non_cleantech['patent_abstract'].progress_apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_842790/1316912123.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  g_patent_cleantech.loc[:, 'patent_title_abstract'] = g_patent_cleantech['patent_title'] + ' [SEP] ' + g_patent_cleantech['patent_abstract']\n",
      "/tmp/ipykernel_842790/1316912123.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  g_patent_cleantech.loc[:, 'label'] = 1\n"
     ]
    }
   ],
   "source": [
    "g_patent_cleantech.loc[:, 'patent_title_abstract'] = g_patent_cleantech['patent_title'] + ' [SEP] ' + g_patent_cleantech['patent_abstract']\n",
    "g_patent_non_cleantech.loc[:, 'patent_title_abstract'] = g_patent_non_cleantech['patent_title'] + ' [SEP] ' + g_patent_non_cleantech['patent_abstract']\n",
    "\n",
    "g_patent_cleantech.loc[:, 'label'] = 1\n",
    "g_patent_non_cleantech.loc[:, 'label'] = 0\n",
    "\n",
    "g_patent = pd.concat([g_patent_cleantech, g_patent_non_cleantech], ignore_index=True)\n",
    "\n",
    "g_patent = g_patent.sort_values(by=['patent_id']).reset_index(drop=True)\n",
    "\n",
    "g_patent['index'] = g_patent.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e9bb63cd3644e7a8d0266d16d96e72b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name_pure = model_name.split('/')[-1]\n",
    "embeddings = model.encode(g_patent['patent_title_abstract'].tolist(), show_progress_bar=True, convert_to_tensor=True, device=device)\n",
    "g_patent[f\"patent_title_abstract_{model_name_pure}_embedding\"] = list(embeddings.cpu().numpy())\n",
    "# g_patent['patent_title_abstract_bert_for_patents_embedding'] = model.encode(g_patent['patent_title_abstract'].tolist(), show_progress_bar=True, convert_to_tensor=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_id</th>\n",
       "      <th>cpc_groups</th>\n",
       "      <th>patent_title</th>\n",
       "      <th>patent_abstract</th>\n",
       "      <th>patent_title_abstract</th>\n",
       "      <th>label</th>\n",
       "      <th>index</th>\n",
       "      <th>patent_title_abstract_distilbert-base-uncased_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000011</td>\n",
       "      <td>[B22, Y02, B22, B29, B29, B29, B22, B29, B29, ...</td>\n",
       "      <td>Supports for sintering additively manufactured...</td>\n",
       "      <td>To reduce distortion in an additively manufact...</td>\n",
       "      <td>Supports for sintering additively manufactured...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.30896538, -0.010423301, 0.29560864, 0.1019...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000017</td>\n",
       "      <td>[Y02, B29, B29, B29, F05, B29, B29, F16, B29, ...</td>\n",
       "      <td>Method for mounting a vortex generator and mou...</td>\n",
       "      <td>The invention relates to a method for securing...</td>\n",
       "      <td>Method for mounting a vortex generator and mou...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.22623001, 0.13069649, 0.36648774, 0.050247...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000021</td>\n",
       "      <td>[Y02, B22, B29, B22, B23, B29, B33, B22, B22, ...</td>\n",
       "      <td>Method for manufacturing threedimensional shap...</td>\n",
       "      <td>There is provided a method for manufacturing a...</td>\n",
       "      <td>Method for manufacturing threedimensional shap...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.37131295, 0.11316093, 0.28202266, -0.02531...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000023</td>\n",
       "      <td>[B29, B29, B29, B29, B33, B29, B33, B33, G05]</td>\n",
       "      <td>Apparatus and method for forming threedimensio...</td>\n",
       "      <td>An apparatus and method for making a threedime...</td>\n",
       "      <td>Apparatus and method for forming threedimensio...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.36689574, 0.17876409, 0.2525317, -0.055100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000025</td>\n",
       "      <td>[Y02, B32, B32, B29, B29, Y10, B32, B29, B32, ...</td>\n",
       "      <td>Optimized crossply orientation in composite la...</td>\n",
       "      <td>A composite laminate has a primary axis of loa...</td>\n",
       "      <td>Optimized crossply orientation in composite la...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[-0.05470236, 0.021735363, 0.25705713, 0.20773...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patent_id                                         cpc_groups  \\\n",
       "0  10000011  [B22, Y02, B22, B29, B29, B29, B22, B29, B29, ...   \n",
       "1  10000017  [Y02, B29, B29, B29, F05, B29, B29, F16, B29, ...   \n",
       "2  10000021  [Y02, B22, B29, B22, B23, B29, B33, B22, B22, ...   \n",
       "3  10000023      [B29, B29, B29, B29, B33, B29, B33, B33, G05]   \n",
       "4  10000025  [Y02, B32, B32, B29, B29, Y10, B32, B29, B32, ...   \n",
       "\n",
       "                                        patent_title  \\\n",
       "0  Supports for sintering additively manufactured...   \n",
       "1  Method for mounting a vortex generator and mou...   \n",
       "2  Method for manufacturing threedimensional shap...   \n",
       "3  Apparatus and method for forming threedimensio...   \n",
       "4  Optimized crossply orientation in composite la...   \n",
       "\n",
       "                                     patent_abstract  \\\n",
       "0  To reduce distortion in an additively manufact...   \n",
       "1  The invention relates to a method for securing...   \n",
       "2  There is provided a method for manufacturing a...   \n",
       "3  An apparatus and method for making a threedime...   \n",
       "4  A composite laminate has a primary axis of loa...   \n",
       "\n",
       "                               patent_title_abstract  label  index  \\\n",
       "0  Supports for sintering additively manufactured...      1      0   \n",
       "1  Method for mounting a vortex generator and mou...      1      1   \n",
       "2  Method for manufacturing threedimensional shap...      1      2   \n",
       "3  Apparatus and method for forming threedimensio...      0      3   \n",
       "4  Optimized crossply orientation in composite la...      1      4   \n",
       "\n",
       "  patent_title_abstract_distilbert-base-uncased_embedding  \n",
       "0  [-0.30896538, -0.010423301, 0.29560864, 0.1019...       \n",
       "1  [-0.22623001, 0.13069649, 0.36648774, 0.050247...       \n",
       "2  [-0.37131295, 0.11316093, 0.28202266, -0.02531...       \n",
       "3  [-0.36689574, 0.17876409, 0.2525317, -0.055100...       \n",
       "4  [-0.05470236, 0.021735363, 0.25705713, 0.20773...       "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_patent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If I want to load precomputed embeddings\n",
    "g_patent.to_csv(f\"/mnt/hdd01/patentsview/Graph Neural Network for EDV-TEK/raw/g_patent_embedding_{model_name_pure}.csv\", index=False)\n",
    "# g_patent = pd.read_csv('/mnt/hdd01/patentsview/Graph Neural Network for EDV-TEK/raw/g_patent_embedding.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignees, Inventors and Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_assignee = pd.read_csv('/mnt/hdd01/patentsview/Raw files/Raw zip files/g_assignee_disambiguated.tsv.zip', sep='\\t', compression='zip', usecols=['patent_id', 'assignee_id', 'disambig_assignee_individual_name_first', 'disambig_assignee_individual_name_last', 'disambig_assignee_organization'], low_memory=False)\n",
    "g_inventor = pd.read_csv('/mnt/hdd01/patentsview/Raw files/Raw zip files/g_inventor_disambiguated.tsv.zip', sep='\\t', compression='zip', usecols=['patent_id', 'inventor_id', 'disambig_inventor_name_first', 'disambig_inventor_name_last'], low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_assignee = g_assignee[g_assignee['patent_id'].isin(g_patent_cleantech['patent_id'].tolist() + g_patent_non_cleantech['patent_id'].tolist())].reset_index(drop=True)\n",
    "g_assignee = g_assignee.sort_values(by=['assignee_id']).reset_index(drop=True)\n",
    "g_inventor = g_inventor[g_inventor['patent_id'].isin(g_patent_cleantech['patent_id'].tolist() + g_patent_non_cleantech['patent_id'].tolist())].reset_index(drop=True)\n",
    "g_inventor = g_inventor.sort_values(by=['inventor_id']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_assignee_nodes = g_assignee[['assignee_id', 'disambig_assignee_individual_name_first', 'disambig_assignee_individual_name_last', 'disambig_assignee_organization']].drop_duplicates().reset_index(drop=True)\n",
    "g_inventor_nodes = g_inventor[['inventor_id', 'disambig_inventor_name_first', 'disambig_inventor_name_last']].drop_duplicates().reset_index(drop=True)\n",
    "g_assignee_nodes['index'] = g_assignee_nodes.index\n",
    "g_inventor_nodes['index'] = g_inventor_nodes.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g_assignee_nodes['assignee_embedding'] = np.random.rand(len(g_assignee_nodes), 1024).tolist()\n",
    "# g_inventor_nodes['inventor_embedding'] = np.random.rand(len(g_inventor_nodes), 1024).tolist()\n",
    "g_assignee_nodes['assignee_embedding'] = np.random.rand(len(g_assignee_nodes), 768).tolist()\n",
    "g_inventor_nodes['inventor_embedding'] = np.random.rand(len(g_inventor_nodes), 768).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patent Citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g_patent_citation = pd.read_csv('/mnt/hdd01/patentsview/Raw files/Raw zip files/g_us_patent_citation.tsv.zip', sep='\\t', compression='zip', usecols=['patent_id', 'citation_patent_id'], low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_patent_citation = g_patent_citation[g_patent_citation['citation_patent_id'].isin(g_patent_cleantech['patent_id'].tolist() + g_patent_non_cleantech['patent_id'].tolist())].reset_index(drop=True)\n",
    "g_patent_citation = g_patent_citation[g_patent_citation['patent_id'].isin(g_patent_cleantech['patent_id'].tolist() + g_patent_non_cleantech['patent_id'].tolist())].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_patent_citation = pd.merge(g_patent_citation, g_patent[['patent_id', 'index']].rename(columns={'index': 'patent_id_index'}), on='patent_id')\n",
    "g_patent_citation = pd.merge(g_patent_citation, g_patent[['patent_id', 'index']].rename(columns={'index': 'citation_patent_id_index'}), left_on='citation_patent_id', right_on='patent_id').drop(columns=['patent_id_y']).rename(columns={'patent_id_x': 'patent_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18401447/18401447 [05:38<00:00, 54356.88it/s]\n"
     ]
    }
   ],
   "source": [
    "patent_edge_index = []\n",
    "for i in tqdm(range(len(g_patent_citation))):\n",
    "    patent_edge_index.append([g_patent_citation['patent_id_index'][i], g_patent_citation['citation_patent_id_index'][i]])\n",
    "    patent_edge_index.append([g_patent_citation['citation_patent_id_index'][i], g_patent_citation['patent_id_index'][i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inventor and Assignee - Patent Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_assignee_patent = pd.merge(g_assignee, g_patent[['patent_id', 'index']].rename(columns={'index': 'patent_id_index'}), on='patent_id')\n",
    "g_assignee_patent = pd.merge(g_assignee_patent, g_assignee_nodes[['assignee_id', 'index']].rename(columns={'index': 'assignee_id_index'}), on='assignee_id')\n",
    "g_inventor_patent = pd.merge(g_inventor, g_patent[['patent_id', 'index']].rename(columns={'index': 'patent_id_index'}), on='patent_id')\n",
    "g_inventor_patent = pd.merge(g_inventor_patent, g_inventor_nodes[['inventor_id', 'index']].rename(columns={'index': 'inventor_id_index'}), on='inventor_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 993034/993034 [00:07<00:00, 127129.48it/s]\n",
      "100%|██████████| 993034/993034 [00:07<00:00, 127618.61it/s]\n",
      "100%|██████████| 2850236/2850236 [00:31<00:00, 89096.46it/s] \n",
      "100%|██████████| 2850236/2850236 [00:22<00:00, 126760.90it/s]\n"
     ]
    }
   ],
   "source": [
    "assignee_patent_edge_index = []\n",
    "for i in tqdm(range(len(g_assignee_patent))):\n",
    "    assignee_patent_edge_index.append([g_assignee_patent['assignee_id_index'][i], g_assignee_patent['patent_id_index'][i]])\n",
    "\n",
    "patent_assignee_edge_index = []\n",
    "for i in tqdm(range(len(g_assignee_patent))):\n",
    "    patent_assignee_edge_index.append([g_assignee_patent['patent_id_index'][i], g_assignee_patent['assignee_id_index'][i]])\n",
    "\n",
    "inventor_patent_edge_index = []\n",
    "for i in tqdm(range(len(g_inventor_patent))):\n",
    "    inventor_patent_edge_index.append([g_inventor_patent['inventor_id_index'][i], g_inventor_patent['patent_id_index'][i]])\n",
    "\n",
    "patent_inventor_edge_index = []\n",
    "for i in tqdm(range(len(g_inventor_patent))):\n",
    "    patent_inventor_edge_index.append([g_inventor_patent['patent_id_index'][i], g_inventor_patent['inventor_id_index'][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g_inventor_nodes.to_csv('/mnt/hdd01/patentsview/Graph Neural Network for EDV-TEK/raw/g_inventor_nodes.csv', index=False)\n",
    "# g_assignee_nodes.to_csv('/mnt/hdd01/patentsview/Graph Neural Network for EDV-TEK/raw/g_assignee_nodes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_edge_index = pd.DataFrame(patent_edge_index, columns=['source', 'target'])\n",
    "assignee_patent_edge_index = pd.DataFrame(assignee_patent_edge_index, columns=['source', 'target'])\n",
    "patent_assignee_edge_index = pd.DataFrame(patent_assignee_edge_index, columns=['source', 'target'])\n",
    "inventor_patent_edge_index = pd.DataFrame(inventor_patent_edge_index, columns=['source', 'target'])\n",
    "patent_inventor_edge_index = pd.DataFrame(patent_inventor_edge_index, columns=['source', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patent_edge_index.to_csv('/mnt/hdd01/patentsview/Graph Neural Network for EDV-TEK/raw/patent_edge_index.csv', index=False)\n",
    "# assignee_patent_edge_index.to_csv('/mnt/hdd01/patentsview/Graph Neural Network for EDV-TEK/raw/assignee_patent_edge_index.csv', index=False)\n",
    "# patent_assignee_edge_index.to_csv('/mnt/hdd01/patentsview/Graph Neural Network for EDV-TEK/raw/patent_assignee_edge_index.csv', index=False)\n",
    "# inventor_patent_edge_index.to_csv('/mnt/hdd01/patentsview/Graph Neural Network for EDV-TEK/raw/inventor_patent_edge_index.csv', index=False)\n",
    "# patent_inventor_edge_index.to_csv('/mnt/hdd01/patentsview/Graph Neural Network for EDV-TEK/raw/patent_inventor_edge_index.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If I want to load precomputed patent embeddings\n",
    "# g_patent = pd.read_csv('/mnt/hdd01/patentsview/Graph Neural Network for EDV-TEK/raw/g_patent_embedding.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_assignee_nodes = g_assignee_nodes.astype(str)\n",
    "g_inventor_nodes = g_inventor_nodes.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print datatypes of g_patent all columns\n",
    "# for col in g_patent.columns:\n",
    "#     print(col, g_patent[col].dtype)\n",
    "\n",
    "# # Print datatypes of g_assignee_nodes all columns\n",
    "# for col in g_assignee_nodes.columns:\n",
    "#     print(col, g_assignee_nodes[col].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_array(str_repr):\n",
    "    return np.fromstring(str_repr.strip('[]'), sep=',')\n",
    "\n",
    "# Open an HDF5 file\n",
    "with h5py.File('/mnt/hdd01/patentsview/Graph Neural Network for EDV-TEK/raw/torch_tek_dataset_distilbert.h5', 'w') as f:\n",
    "    # Save node data\n",
    "    # f.create_dataset('g_patent/x', data=np.stack(g_patent['patent_title_abstract_bert_for_patents_embedding'].apply(string_to_array).values))\n",
    "    f.create_dataset('g_patent/x', data=np.stack(g_patent[f\"patent_title_abstract_{model_name_pure}_embedding\"].values))\n",
    "    f.create_dataset('g_patent/y', data=g_patent['label'].values.astype(np.int64))\n",
    "    f.create_dataset('g_assignee_nodes/x', data=np.stack(g_assignee_nodes['assignee_embedding'].apply(string_to_array).values))\n",
    "    f.create_dataset('g_inventor_nodes/x', data=np.stack(g_inventor_nodes['inventor_embedding'].apply(string_to_array).values))\n",
    "    \n",
    "    # Save edge indices\n",
    "    f.create_dataset('patent_edge_index', data=patent_edge_index.values, dtype=np.int64)\n",
    "    f.create_dataset('assignee_patent_edge_index', data=assignee_patent_edge_index.values, dtype=np.int64)\n",
    "    f.create_dataset('patent_assignee_edge_index', data=patent_assignee_edge_index.values, dtype=np.int64)\n",
    "    f.create_dataset('inventor_patent_edge_index', data=inventor_patent_edge_index.values, dtype=np.int64)\n",
    "    f.create_dataset('patent_inventor_edge_index', data=patent_inventor_edge_index.values, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate (heterogeneous) data model\n",
    "- https://pytorch-geometric.readthedocs.io/en/latest/tutorial/create_dataset.html\n",
    "- https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/datasets/ogb_mag.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heterogeneous Dataset with Patents, Assignees and Inventors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatentHeteroDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(PatentHeteroDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data = None\n",
    "        # processed_path = osp.join(self.processed_dir, self.processed_file_names)\n",
    "        # if osp.exists(processed_path):\n",
    "        #     self.data = torch.load(processed_path)\n",
    "        # else:\n",
    "        self.process()\n",
    "\n",
    "    @property\n",
    "    def num_classes(self):\n",
    "        return 2\n",
    "\n",
    "    @property\n",
    "    def raw_dir(self):\n",
    "        return '/mnt/hdd01/patentsview/Graph Neural Network for EDV-TEK/raw/'\n",
    "    \n",
    "    @property\n",
    "    def processed_dir(self):\n",
    "        return '/mnt/hdd01/patentsview/Graph Neural Network for EDV-TEK/processed/'\n",
    "\n",
    "    # @property\n",
    "    # def raw_file_names(self):\n",
    "    #     return [\n",
    "    #         'g_patent_embedding.csv',\n",
    "    #         'g_inventor_nodes.csv',\n",
    "    #         'g_assignee_nodes.csv',\n",
    "    #         'patent_edge_index.csv',\n",
    "    #         'assignee_edge_index.csv',\n",
    "    #         'inventor_edge_index.csv'\n",
    "    #     ]\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [\n",
    "            'torch_tek_dataset_distilbert.h5' # Adjust to correct model\n",
    "        ]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return 'gnn_tek_data_distilbert.pt' # Adjust to correct model\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    # def process(self): # Process for reading from csv using pandas\n",
    "    #     # Initialize HeteroData object\n",
    "    #     data = HeteroData()\n",
    "\n",
    "    #     # Load and process node features\n",
    "    #     # Assuming that the feature columns contain lists or arrays of features\n",
    "    #     g_patent = pd.read_csv(osp.join(self.raw_dir, 'g_patent_embedding.csv'), usecols=['index', 'patent_title_abstract_bert_for_patents_embedding', 'label'])\n",
    "    #     g_inventor_nodes = pd.read_csv(osp.join(self.raw_dir, 'g_inventor_nodes.csv'))\n",
    "    #     g_assignee_nodes = pd.read_csv(osp.join(self.raw_dir, 'g_assignee_nodes.csv'))\n",
    "\n",
    "    #     data['patent'].x = torch.tensor(np.stack(g_patent['patent_title_abstract_bert_for_patents_embedding'].apply(eval).values), dtype=torch.float)\n",
    "    #     data['patent_inventor'].x = torch.tensor(np.stack(g_inventor_nodes['inventor_embedding'].apply(eval).values), dtype=torch.float)\n",
    "    #     data['patent_assignee'].x = torch.tensor(np.stack(g_assignee_nodes['assignee_embedding'].apply(eval).values), dtype=torch.float)\n",
    "\n",
    "    #     # Load and process edge indices\n",
    "    #     patent_edge_index = pd.read_csv(osp.join(self.raw_dir, 'patent_edge_index.csv')).values\n",
    "    #     inventor_edge_index = pd.read_csv(osp.join(self.raw_dir, 'inventor_edge_index.csv')).values\n",
    "    #     assignee_edge_index = pd.read_csv(osp.join(self.raw_dir, 'assignee_edge_index.csv')).values\n",
    "\n",
    "    #     data['patent', 'cites', 'patent'].edge_index = torch.tensor(patent_edge_index, dtype=torch.long).t().contiguous()\n",
    "    #     data['patent_inventor', 'inventor_of', 'patent'].edge_index = torch.tensor(inventor_edge_index, dtype=torch.long).t().contiguous()\n",
    "    #     data['patent_assignee', 'assignee_of', 'patent'].edge_index = torch.tensor(assignee_edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "    #     # Load and process labels\n",
    "    #     data['patent'].y = torch.tensor(g_patent['label'].values, dtype=torch.long)\n",
    "\n",
    "    #     if self.pre_transform is not None:\n",
    "    #         data = self.pre_transform(data)\n",
    "\n",
    "    #     self.data = data  # Save the processed data to self.data\n",
    "    #     torch.save(data, osp.join(self.processed_dir, self.processed_file_names))\n",
    "\n",
    "    def process(self):\n",
    "        # Initialize HeteroData object\n",
    "        data = HeteroData()\n",
    "    \n",
    "        # Open an HDF5 file\n",
    "        with h5py.File(osp.join(self.raw_dir, 'torch_tek_dataset_distilbert.h5'), 'r') as f:\n",
    "            # Load and process node features\n",
    "            data['patent'].x = torch.tensor(f['g_patent/x'][:], dtype=torch.float)\n",
    "            data['patent'].y = torch.tensor(f['g_patent/y'][:], dtype=torch.long)\n",
    "            data['patent_inventor'].x = torch.tensor(f['g_inventor_nodes/x'][:], dtype=torch.float)\n",
    "            data['patent_assignee'].x = torch.tensor(f['g_assignee_nodes/x'][:], dtype=torch.float)\n",
    "            \n",
    "            # Load and process edge indices\n",
    "            data['patent', 'cites', 'patent'].edge_index = torch.tensor(f['patent_edge_index'][:], dtype=torch.long).t().contiguous()\n",
    "            data['patent_inventor', 'inventor_of', 'patent'].edge_index = torch.tensor(f['inventor_patent_edge_index'][:], dtype=torch.long).t().contiguous()\n",
    "            data['patent_assignee', 'assignee_of', 'patent'].edge_index = torch.tensor(f['assignee_patent_edge_index'][:], dtype=torch.long).t().contiguous()\n",
    "            data['patent', 'has_assignee', 'patent_assignee'].edge_index = torch.tensor(f['patent_assignee_edge_index'][:], dtype=torch.long).t().contiguous()\n",
    "            data['patent', 'has_inventor', 'patent_inventor'].edge_index = torch.tensor(f['patent_inventor_edge_index'][:], dtype=torch.long).t().contiguous()\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data = self.pre_transform(data)\n",
    "\n",
    "        # Create train_mask, val_mask, and test_mask\n",
    "        data['patent'].train_mask = torch.zeros(data['patent'].num_nodes, dtype=torch.bool)\n",
    "        data['patent'].val_mask = torch.zeros(data['patent'].num_nodes, dtype=torch.bool)\n",
    "        data['patent'].test_mask = torch.zeros(data['patent'].num_nodes, dtype=torch.bool)\n",
    "        data['patent'].train_mask[:int(0.8*data['patent'].num_nodes)] = 1\n",
    "        data['patent'].val_mask[int(0.8*data['patent'].num_nodes):int(0.9*data['patent'].num_nodes)] = 1\n",
    "        data['patent'].test_mask[int(0.9*data['patent'].num_nodes):] = 1\n",
    "\n",
    "        # Diagnostic print statements\n",
    "        print(\"Data keys after processing:\", data.keys())\n",
    "        print(\"Node types and their feature shapes:\")\n",
    "        for node_type, node_data in data.node_items():\n",
    "            print(f\"Node type: {node_type}\")\n",
    "            for key, item in node_data.items():\n",
    "                if key == 'x' or key == 'y':\n",
    "                    print(f\"Features ({key}) shape:\", item.size())\n",
    "\n",
    "        print(\"Edge types and their index shapes:\")\n",
    "        for edge_type, edge_data in data.edge_items():\n",
    "            print(f\"Edge type: {edge_type}\")\n",
    "            if 'edge_index' in edge_data:\n",
    "                print(\"Edge index shape:\", edge_data['edge_index'].size())\n",
    "            else:\n",
    "                print(f\"{edge_type} has no edge index.\")\n",
    "        # print(\"Train, validation, and test masks:\")\n",
    "        # print(\"Train mask:\", data['patent'].train_mask)\n",
    "        # print(\"Validation mask:\", data['patent'].val_mask)\n",
    "        # print(\"Test mask:\", data['patent'].test_mask)\n",
    "        \n",
    "\n",
    "        self.data = data  # Save the processed data to self.data\n",
    "        torch.save(data, osp.join(self.processed_dir, self.processed_file_names))\n",
    "\n",
    "    def len(self):\n",
    "        return 1\n",
    "\n",
    "    def get(self, idx):\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data keys after processing: ['val_mask', 'train_mask', 'y', 'test_mask', 'x', 'edge_index']\n",
      "Node types and their feature shapes:\n",
      "Node type: patent\n",
      "Features (x) shape: torch.Size([1031566, 768])\n",
      "Features (y) shape: torch.Size([1031566])\n",
      "Node type: patent_inventor\n",
      "Features (x) shape: torch.Size([957088, 768])\n",
      "Node type: patent_assignee\n",
      "Features (x) shape: torch.Size([108717, 768])\n",
      "Edge types and their index shapes:\n",
      "Edge type: ('patent', 'cites', 'patent')\n",
      "Edge index shape: torch.Size([2, 36802894])\n",
      "Edge type: ('patent_inventor', 'inventor_of', 'patent')\n",
      "Edge index shape: torch.Size([2, 2850236])\n",
      "Edge type: ('patent_assignee', 'assignee_of', 'patent')\n",
      "Edge index shape: torch.Size([2, 993034])\n",
      "Edge type: ('patent', 'has_assignee', 'patent_assignee')\n",
      "Edge index shape: torch.Size([2, 993034])\n",
      "Edge type: ('patent', 'has_inventor', 'patent_inventor')\n",
      "Edge index shape: torch.Size([2, 2850236])\n"
     ]
    }
   ],
   "source": [
    "dataset = PatentHeteroDataset(root='/mnt/hdd01/patentsview/Graph Neural Network for EDV-TEK/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "PatentDataset = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node type: patent\n",
      "Features (x) shape: torch.Size([1031566, 768])\n",
      "Labels (y) shape: torch.Size([1031566])\n",
      "Node type: patent_inventor\n",
      "Features (x) shape: torch.Size([1121503, 768])\n",
      "Node type: patent_assignee\n",
      "Features (x) shape: torch.Size([126076, 768])\n",
      "Edge type: ('patent', 'cites', 'patent')\n",
      "Edge index shape: torch.Size([2, 7331458])\n",
      "Edge type: ('patent_inventor', 'inventor_of', 'patent')\n",
      "Edge index shape: torch.Size([2, 2756942])\n",
      "Edge type: ('patent_assignee', 'assignee_of', 'patent')\n",
      "Edge index shape: torch.Size([2, 986154])\n",
      "Edge type: ('patent', 'has_assignee', 'patent_assignee')\n",
      "Edge index shape: torch.Size([2, 986154])\n",
      "Edge type: ('patent', 'has_inventor', 'patent_inventor')\n",
      "Edge index shape: torch.Size([2, 2756942])\n"
     ]
    }
   ],
   "source": [
    "for node_type in PatentDataset.node_types:\n",
    "    print(f\"Node type: {node_type}\")\n",
    "    print(f\"Features (x) shape: {PatentDataset[node_type].x.shape}\")\n",
    "    if 'y' in PatentDataset[node_type]:\n",
    "        print(f\"Labels (y) shape: {PatentDataset[node_type].y.shape}\")\n",
    "\n",
    "for edge_type in PatentDataset.edge_types:\n",
    "    print(f\"Edge type: {edge_type}\")\n",
    "    print(f\"Edge index shape: {PatentDataset[edge_type].edge_index.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homogeneous Dataset with Patent and Patent Citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestPatentHomoDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(TestPatentHomoDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data = None\n",
    "        self.process()\n",
    "\n",
    "    @property\n",
    "    def num_classes(self):\n",
    "        return 2\n",
    "\n",
    "    @property\n",
    "    def raw_dir(self):\n",
    "        return '/mnt/hdd01/patentsview/Graph Neural Network for EDV-TEK/raw/'\n",
    "\n",
    "    @property\n",
    "    def processed_dir(self):\n",
    "        return '/mnt/hdd01/patentsview/Graph Neural Network for EDV-TEK/processed/'\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['torch_tek_dataset_distilbert.h5']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return 'gnn_tek_data_distilbert.pt'\n",
    "\n",
    "    def process(self):\n",
    "        data = Data()\n",
    "\n",
    "        with h5py.File(osp.join(self.raw_dir, 'torch_tek_dataset_distilbert.h5'), 'r') as f:\n",
    "            # Load and process node features and labels for patents\n",
    "            data.x = torch.tensor(f['g_patent/x'][:], dtype=torch.float)\n",
    "            data.y = torch.tensor(f['g_patent/y'][:], dtype=torch.long)\n",
    "            \n",
    "            # Load and process edge indices for 'patent' 'cites' 'patent'\n",
    "            data.edge_index = torch.tensor(f['patent_edge_index'][:], dtype=torch.long).t().contiguous()\n",
    "\n",
    "            num_nodes = data.x.size(0)\n",
    "\n",
    "            # Create train_mask, val_mask, and test_mask\n",
    "            data.train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "            data.val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "            data.test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "            \n",
    "            # Define splits\n",
    "            train_end = int(0.8 * num_nodes)\n",
    "            val_end = int(0.9 * num_nodes)\n",
    "\n",
    "            data.train_mask[:train_end] = 1\n",
    "            data.val_mask[train_end:val_end] = 1\n",
    "            data.test_mask[val_end:] = 1\n",
    "\n",
    "        self.data = data\n",
    "        torch.save(data, osp.join(self.processed_dir, self.processed_file_names))\n",
    "\n",
    "    def len(self):\n",
    "        return 1\n",
    "\n",
    "    def get(self, idx):\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TestPatentHomoDataset(root='/mnt/hdd01/patentsview/Graph Neural Network for EDV-TEK/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_PatentDataset = test_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build PyTorch Geoemtric Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper functions for visualization\n",
    "def visualize_graph(G, color):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    nx.draw_networkx(G, pos=nx.spring_layout(G, seed=42), with_labels=False,\n",
    "                     node_color=color, cmap=\"Set2\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_embedding(h, color, epoch=None, loss=None):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    h = h.detach().cpu().numpy()\n",
    "    plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap=\"Set2\")\n",
    "    if epoch is not None and loss is not None:\n",
    "        plt.xlabel(f'Epoch: {epoch}, Loss: {loss.item():.4f}', fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define NN architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.HeteroConv.html#torch_geometric.nn.conv.HeteroConv\n",
    "- https://github.com/pyg-team/pytorch_geometric/issues/4657\n",
    "- https://pytorch-geometric.readthedocs.io/en/latest/modules/loader.html#torch_geometric.loader.NeighborLoader\n",
    "- https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.MessagePassing.html#torch_geometric.nn.conv.MessagePassing - *if passed to GNN, Message Passing will be performed on the graph*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Architecture for Heteregeneous Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplifiedHeteroGCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_node_features_dict, num_classes):\n",
    "        super(SimplifiedHeteroGCN, self).__init__()\n",
    "        torch.manual_seed(42)  # For reproducible results\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(p=0.2)  # Define dropout layer\n",
    "\n",
    "        # Define a SAGEConv for essential relations\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('patent', 'cites', 'patent'): SAGEConv(num_node_features_dict['patent'], hidden_channels, add_self_loops=True)\n",
    "        }, aggr='mean')\n",
    "\n",
    "        self.conv2 = HeteroConv({\n",
    "            ('patent', 'cites', 'patent'): SAGEConv(hidden_channels, hidden_channels, add_self_loops=True)\n",
    "        }, aggr='mean')\n",
    "\n",
    "        # Linear layer for classifying patents\n",
    "        self.lin = torch.nn.Linear(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x_dict, edge_index_dict = data.x_dict, data.edge_index_dict\n",
    "        \n",
    "        # Apply dropout to 'patent' node features\n",
    "        x_dict['patent'] = self.dropout(x_dict['patent'])\n",
    "\n",
    "        # First convolution layer\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
    "        x_dict = {key: F.relu(x) for key, x in x_dict.items()}\n",
    "\n",
    "        # Second convolution layer\n",
    "        x_dict = self.conv2(x_dict, edge_index_dict)\n",
    "        x_dict = {key: F.relu(x) for key, x in x_dict.items()}\n",
    "\n",
    "        # Predictions for 'patent' node embeddings\n",
    "        out = self.lin(x_dict['patent'])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroGCN(MessagePassing):\n",
    "    def __init__(self, hidden_channels, num_node_features_dict, num_classes):\n",
    "        super(HeteroGCN, self).__init__(aggr='mean')\n",
    "        torch.manual_seed(42) # For reproducible results\n",
    "        \n",
    "        # Define a separate SAGEConv for each edge type with correct input feature sizes\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('patent', 'cites', 'patent'): SAGEConv(num_node_features_dict['patent'], hidden_channels, add_self_loops=True),\n",
    "            ('patent_inventor', 'inventor_of', 'patent'): SAGEConv(num_node_features_dict['patent_inventor'], hidden_channels, add_self_loops=True),\n",
    "            ('patent_assignee', 'assignee_of', 'patent'): SAGEConv(num_node_features_dict['patent_assignee'], hidden_channels, add_self_loops=True),\n",
    "            ('patent', 'has_assignee', 'patent_assignee'): SAGEConv(num_node_features_dict['patent'], hidden_channels, add_self_loops=True),\n",
    "            ('patent', 'has_inventor', 'patent_inventor'): SAGEConv(num_node_features_dict['patent'], hidden_channels, add_self_loops=True)\n",
    "        }, aggr='mean')\n",
    "\n",
    "        self.conv2 = HeteroConv({\n",
    "            ('patent', 'cites', 'patent'): SAGEConv(hidden_channels, hidden_channels, add_self_loops=True),\n",
    "            ('patent_inventor', 'inventor_of', 'patent'): SAGEConv(hidden_channels, hidden_channels, add_self_loops=True),\n",
    "            ('patent_assignee', 'assignee_of', 'patent'): SAGEConv(hidden_channels, hidden_channels, add_self_loops=True),\n",
    "            ('patent', 'has_assignee', 'patent_assignee'): SAGEConv(hidden_channels, hidden_channels, add_self_loops=True),\n",
    "            ('patent', 'has_inventor', 'patent_inventor'): SAGEConv(hidden_channels, hidden_channels, add_self_loops=True)\n",
    "        }, aggr='mean')\n",
    "\n",
    "        # Linear layer for classifying patents\n",
    "        self.lin = torch.nn.Linear(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x_dict, edge_index_dict = data.x_dict, data.edge_index_dict\n",
    "\n",
    "        # Include dropout for regularization\n",
    "        x_dict['patent'] = F.dropout(x_dict['patent'], p=0.2, training=self.training)\n",
    "\n",
    "        # First convolution layer\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
    "        x_dict = {key: x.relu() for key, x in x_dict.items()}\n",
    "\n",
    "        # Second convolution layer\n",
    "        x_dict = self.conv2(x_dict, edge_index_dict)\n",
    "        x_dict = {key: x.relu() for key, x in x_dict.items()}\n",
    "\n",
    "        # Only use the 'patent' node embeddings for the final prediction\n",
    "        out = self.lin(x_dict['patent'])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_node_features_dict = {'patent': 1024, 'patent_inventor': 1024, 'patent_assignee': 1024}\n",
    "num_node_features_dict = {'patent': 768, 'patent_inventor': 768, 'patent_assignee': 768}\n",
    "num_classes = 2\n",
    "\n",
    "# model = HeteroGCN(hidden_channels=64, num_node_features_dict=num_node_features_dict, num_classes=num_classes)\n",
    "model = HeteroGCN(hidden_channels=512, num_node_features_dict=num_node_features_dict, num_classes=num_classes)\n",
    "# model = SimplifiedHeteroGCN(hidden_channels=512, num_node_features_dict=num_node_features_dict, num_classes=num_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Architecture for Homogeneous Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestGCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_classes):\n",
    "        super().__init__()\n",
    "        # torch.manual_seed(42)  # For reproducible results\n",
    "        self.conv1 = GCNConv(768, num_classes)\n",
    "        # self.lin2 = torch.nn.Linear(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        # x = F.dropout(x, p=0.5, training=self.training)\n",
    "        # x = self.lin2(x)\n",
    "        return x\n",
    "\n",
    "model = TestGCN(hidden_channels=16, num_classes=2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighbor Loader\n",
    "- https://pytorch-geometric.readthedocs.io/en/latest/modules/loader.html *If data does not fully fit into GPU memory, we can use the NeighborLoader to perform mini-batch training.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neighbor Loader for Heterogeneous Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "PatentDataset = PatentDataset.to(device)\n",
    "train_loader = NeighborLoader(PatentDataset, num_neighbors=[100], batch_size=512, shuffle=True, input_nodes=('patent', PatentDataset['patent'].train_mask))\n",
    "test_loader = NeighborLoader(PatentDataset, num_neighbors=[100], batch_size=512, shuffle=False, input_nodes=('patent', PatentDataset['patent'].test_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neighbor Loader for Homogeneous Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "test_PatentDataset = test_PatentDataset.to(device)\n",
    "train_loader = NeighborLoader(test_PatentDataset, num_neighbors=[100], batch_size=512, shuffle=True)\n",
    "test_loader = NeighborLoader(test_PatentDataset, num_neighbors=[100], batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Print embeddings of first 5 nodes of node type 'patent' before training\n",
    "# print(PatentDataset['patent'].x[:5])\n",
    "# print(test_PatentDataset.x[:5])\n",
    "# print(test_PatentDataset.y[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_batches = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        try:\n",
    "            out = model(batch) # For Heterogeneous NN\n",
    "            # out = model(batch.x, batch.edge_index) # For Homogeneous NN\n",
    "            loss = criterion(out[batch['patent'].train_mask], batch['patent'].y[batch['patent'].train_mask]) # For Hetereogeneous NN \n",
    "            # loss = criterion(out[batch.train_mask], batch.y[batch.train_mask]) # For Homogeneous NN\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_batches += 1\n",
    "        except Exception as e:\n",
    "            print(\"Error during training:\", e)\n",
    "            raise\n",
    "            \n",
    "    return total_loss / total_batches if total_batches else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch in test_loader:\n",
    "        batch = batch.to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(batch)\n",
    "            # out = model(batch.x, batch.edge_index)\n",
    "            pred = out.argmax(dim=1)\n",
    "            \n",
    "            # Assuming batch['patent'].test_mask is a boolean mask\n",
    "            test_mask = batch['patent'].test_mask # For Hetereogeneous NN \n",
    "            # test_mask = batch.test_mask # For Homogeneous NN\n",
    "            test_labels = batch['patent'].y # For Hetereogeneous NN \n",
    "            # test_labels = batch.y # For Homogeneous NN\n",
    "\n",
    "            # Update correct and total counts\n",
    "            correct += int((pred[test_mask] == test_labels[test_mask]).sum())\n",
    "            total += int(test_mask.sum())\n",
    "\n",
    "    test_acc = correct / total\n",
    "    return test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.5377, Test Acc: 0.6856\n",
      "Epoch: 002, Loss: 0.5141, Test Acc: 0.7243\n",
      "Epoch: 003, Loss: 0.5119, Test Acc: 0.7082\n",
      "Epoch: 004, Loss: 0.5104, Test Acc: 0.7282\n",
      "Epoch: 005, Loss: 0.5094, Test Acc: 0.7202\n",
      "Epoch: 006, Loss: 0.5088, Test Acc: 0.6956\n",
      "Epoch: 007, Loss: 0.5085, Test Acc: 0.7323\n",
      "Epoch: 008, Loss: 0.5080, Test Acc: 0.7236\n",
      "Epoch: 009, Loss: 0.5080, Test Acc: 0.7270\n",
      "Epoch: 010, Loss: 0.5076, Test Acc: 0.7319\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    loss = train()\n",
    "    test_acc = test()\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
