{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, URL, text\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_object = URL.create(\n",
    "    drivername=\"\",\n",
    "    username=\"\",\n",
    "    password=\"\",\n",
    "    host=\"\",\n",
    "    port=\"\",\n",
    "    database=\"\"\n",
    ")\n",
    "engine = create_engine(url_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Indices on Query Columns (only required once!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_ep_index = \"\"\"CREATE INDEX ep_index ON ep_fulltext_data(epo_publn_nr, publn_auth);\"\"\"\n",
    "# query_us_brf_summary_index = \"\"\"CREATE INDEX us_brf_summary_index ON us_brf_summary(patent_id, publn_auth);\"\"\"\n",
    "# query_us_claims_index = \"\"\"CREATE INDEX us_claims_index ON us_claims(patent_id, publn_auth);\"\"\"\n",
    "# query_us_description_index = \"\"\"CREATE INDEX us_description_index ON us_description(patent_id, publn_auth);\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with engine.connect() as connection:\n",
    "#     connection.execute(text(query_ep_index))\n",
    "#     connection.execute(text(query_us_brf_summary_index))\n",
    "#     connection.execute(text(query_us_claims_index))\n",
    "#     connection.execute(text(query_us_description_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Cleantech Patents from PATSTAT (only granted and EP or US patents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPC Y02 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_cpc_index = \"\"\"CREATE INDEX idx_cpc_class_symbol ON tls224_appln_cpc(cpc_class_symbol);\"\"\" # only required once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_cpc_y02 = \"\"\"\n",
    "    SELECT a.appln_id, a.cpc_class_symbol\n",
    "    FROM tls224_appln_cpc a\n",
    "    JOIN tls201_appln b ON a.appln_id = b.appln_id\n",
    "    WHERE (a.cpc_class_symbol LIKE 'Y02A%' OR\n",
    "           a.cpc_class_symbol LIKE 'Y02B%' OR\n",
    "           a.cpc_class_symbol LIKE 'Y02C%' OR\n",
    "           a.cpc_class_symbol LIKE 'Y02D%' OR\n",
    "           a.cpc_class_symbol LIKE 'Y02E%' OR\n",
    "           a.cpc_class_symbol LIKE 'Y02P%' OR\n",
    "           a.cpc_class_symbol LIKE 'Y02T%' OR\n",
    "           a.cpc_class_symbol LIKE 'Y02W%')\n",
    "      AND b.appln_auth IN ('EP', 'US')\n",
    "      AND b.granted = 'Y';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as connection:\n",
    "    # connection.execute(text(query_cpc_index)) # Only required once\n",
    "    df_cpc = pd.read_sql_query(text(query_cpc_y02), connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_cpc.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subsume Patents per appln_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df.groupby('appln_id').agg({\n",
    "    'cpc_class_symbol': lambda x: list(x)\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Patent Fulltext Data for appln_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Temp Table with appln_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "appln_ids = df_grouped['appln_id'].tolist()\n",
    "\n",
    "# Create a temporary table and insert application IDs\n",
    "temp_table_query = \"\"\"\n",
    "    DROP TABLE IF EXISTS temp_appln_ids;\n",
    "    CREATE TEMP TABLE temp_appln_ids (appln_id TEXT);\n",
    "\"\"\"\n",
    "insert_query = text(\"INSERT INTO temp_appln_ids (appln_id) VALUES (:appln_id)\")\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(temp_table_query))\n",
    "    for id in appln_ids:\n",
    "        connection.execute(insert_query, {'appln_id': id})\n",
    "    connection.commit()\n",
    "\n",
    "    # Perform the join query to extract all valid publn_nr per appln_id\n",
    "    join_query = \"\"\"\n",
    "        SELECT t1.appln_id, t2.publn_auth, t2.publn_nr, t2.publn_date, t2. pat_publn_id\n",
    "        FROM temp_appln_ids t1\n",
    "        JOIN (\n",
    "            SELECT appln_id, publn_auth, publn_nr, publn_date, pat_publn_id\n",
    "            FROM tls211_pat_publn\n",
    "        ) t2 ON t1.appln_id = t2.appln_id;\n",
    "    \"\"\"\n",
    "    result = connection.execute(text(join_query))\n",
    "    df_temp_publn = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "\n",
    "df_temp_publn['publn_nr'] = df_temp_publn['publn_nr'].astype(str)\n",
    "shortest_publn_nr_idx = df_temp_publn.groupby('appln_id')['publn_nr'].apply(lambda x: x.str.len().idxmin())\n",
    "df_shortest_publn = df_temp_publn.loc[shortest_publn_nr_idx]\n",
    "\n",
    "# Insert the filtered results back into the database\n",
    "temp_table_with_publn_query = \"\"\"\n",
    "    DROP TABLE IF EXISTS temp_appln_ids_with_publn;\n",
    "    CREATE TEMP TABLE temp_appln_ids_with_publn (appln_id TEXT, publn_auth TEXT, publn_nr TEXT, publn_date DATE, pat_publn_id TEXT);\n",
    "    CREATE INDEX temp_appln_ids_with_publn_index ON temp_appln_ids_with_publn(publn_nr, publn_auth);\n",
    "\"\"\"\n",
    "insert_filtered_query = text(\"INSERT INTO temp_appln_ids_with_publn (appln_id, publn_auth, publn_nr, publn_date, pat_publn_id) VALUES (:appln_id, :publn_auth, :publn_nr, :publn_date, :pat_publn_id)\")\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(temp_table_with_publn_query))\n",
    "    for _, row in df_shortest_publn.iterrows():\n",
    "        connection.execute(insert_filtered_query, {'appln_id': row['appln_id'], 'publn_auth': row['publn_auth'], 'publn_nr': row['publn_nr'], 'publn_date': row['publn_date'], 'pat_publn_id': row['pat_publn_id']})\n",
    "    connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(770168, 770168)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_grouped), len(df_shortest_publn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appln_id</th>\n",
       "      <th>cpc_class_symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101891</td>\n",
       "      <td>[Y02P  20/52]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101897</td>\n",
       "      <td>[Y02E  60/50]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101926</td>\n",
       "      <td>[Y02B  10/10, Y02B  10/20, Y02B  10/70, Y02E  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101976</td>\n",
       "      <td>[Y02T  10/12, Y02T  10/40]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101984</td>\n",
       "      <td>[Y02D  30/00]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  appln_id                                   cpc_class_symbol\n",
       "0   101891                                      [Y02P  20/52]\n",
       "1   101897                                      [Y02E  60/50]\n",
       "2   101926  [Y02B  10/10, Y02B  10/20, Y02B  10/70, Y02E  ...\n",
       "3   101976                         [Y02T  10/12, Y02T  10/40]\n",
       "4   101984                                      [Y02D  30/00]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appln_id</th>\n",
       "      <th>publn_auth</th>\n",
       "      <th>publn_nr</th>\n",
       "      <th>publn_date</th>\n",
       "      <th>pat_publn_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>412135</th>\n",
       "      <td>101891</td>\n",
       "      <td>EP</td>\n",
       "      <td>1360181</td>\n",
       "      <td>2008-10-08</td>\n",
       "      <td>289379223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703992</th>\n",
       "      <td>101897</td>\n",
       "      <td>EP</td>\n",
       "      <td>1333516</td>\n",
       "      <td>2006-12-13</td>\n",
       "      <td>387634414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176854</th>\n",
       "      <td>101926</td>\n",
       "      <td>EP</td>\n",
       "      <td>1711753</td>\n",
       "      <td>2010-08-18</td>\n",
       "      <td>323646172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067937</th>\n",
       "      <td>101976</td>\n",
       "      <td>EP</td>\n",
       "      <td>2013456</td>\n",
       "      <td>2010-10-13</td>\n",
       "      <td>327969544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272762</th>\n",
       "      <td>101984</td>\n",
       "      <td>EP</td>\n",
       "      <td>2028791</td>\n",
       "      <td>2012-07-04</td>\n",
       "      <td>365139097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        appln_id publn_auth publn_nr  publn_date pat_publn_id\n",
       "412135    101891         EP  1360181  2008-10-08    289379223\n",
       "703992    101897         EP  1333516  2006-12-13    387634414\n",
       "176854    101926         EP  1711753  2010-08-18    323646172\n",
       "1067937   101976         EP  2013456  2010-10-13    327969544\n",
       "1272762   101984         EP  2028791  2012-07-04    365139097"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shortest_publn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns ... from df_shortest_publn and merge with df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract cited patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total citations extracted: 18330656\n"
     ]
    }
   ],
   "source": [
    "# Query to extract citation relationships\n",
    "citation_query = \"\"\"\n",
    "    SELECT t1.appln_id, t1.publn_auth, t1.publn_nr, t1.publn_date, t1.pat_publn_id, \n",
    "           t2.cited_pat_publn_id\n",
    "    FROM temp_appln_ids_with_publn t1\n",
    "    JOIN tls212_citation t2 ON t1.pat_publn_id = t2.pat_publn_id\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and create DataFrame with citation data\n",
    "with engine.connect() as connection:\n",
    "    df_citations = pd.read_sql_query(text(citation_query), connection)\n",
    "    \n",
    "# Display the first few rows to verify the data\n",
    "print(f\"Total citations extracted: {len(df_citations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique set of cleantech patent publication IDs\n",
    "cleantech_pat_publn_ids = set(df_citations['pat_publn_id'].unique())\n",
    "\n",
    "# Filter to include only citations where both citing and cited patents are cleantech patents\n",
    "df_cleantech_citations = df_citations[df_citations['cited_pat_publn_id'].isin(cleantech_pat_publn_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from pat_publn_id to appln_id using our existing data\n",
    "pat_to_appln_mapping = dict(zip(df_citations['pat_publn_id'], df_citations['appln_id']))\n",
    "\n",
    "# Function to map cited_pat_publn_id to cited_appln_id\n",
    "def get_cited_appln_ids(cited_pat_ids):\n",
    "    return [pat_to_appln_mapping.get(pat_id) for pat_id in cited_pat_ids if pat_id in pat_to_appln_mapping]\n",
    "\n",
    "# Aggregate by appln_id\n",
    "df_cleantech_citations_agg = df_cleantech_citations.groupby('appln_id').agg({\n",
    "    'publn_auth': 'first',\n",
    "    'publn_nr': 'first', \n",
    "    'publn_date': 'first',\n",
    "    'pat_publn_id': 'first',\n",
    "    'cited_pat_publn_id': lambda x: list(x)\n",
    "}).reset_index()\n",
    "\n",
    "# Add the cited_appln_id list column\n",
    "df_cleantech_citations_agg['cited_appln_id'] = df_cleantech_citations_agg['cited_pat_publn_id'].apply(get_cited_appln_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Title and Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_title_abstr = \"\"\"\n",
    "    SELECT ids.appln_id, ids.publn_nr, ids.publn_auth, title.appln_title, abstract.appln_abstract\n",
    "    FROM temp_appln_ids_with_publn ids\n",
    "    JOIN tls202_appln_title title ON ids.appln_id = title.appln_id AND title.appln_title_lg = 'en'\n",
    "    JOIN tls203_appln_abstr abstract ON ids.appln_id = abstract.appln_id AND abstract.appln_abstract_lg = 'en'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as connection:\n",
    "    df_title_abstr = pd.read_sql_query(text(query_title_abstr), connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract US Claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as connection:\n",
    "    query_us_claims = \"\"\"\n",
    "        SELECT t1.*, t2.*\n",
    "        FROM temp_appln_ids_with_publn t1\n",
    "        JOIN us_claims t2 ON t1.publn_nr = t2.patent_id AND t1.publn_auth = t2.publn_auth;\n",
    "    \"\"\"\n",
    "    df_us_claims = pd.read_sql(query_us_claims, connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_claims = df_us_claims.dropna(subset=['claim_text'])\n",
    "df_us_claims.sort_values(by=['patent_id', 'claim_sequence'], inplace=True)\n",
    "df_us_claims_grouped = df_us_claims.groupby('appln_id').agg({\n",
    "    'patent_id': 'first',\n",
    "    'claim_text': list\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row):\n",
    "    claim_fulltext = ' '.join(re.sub(r'^\\d+\\.\\s', ' ', text) for text in row['claim_text'])\n",
    "    return pd.Series({'claim_fulltext': claim_fulltext})\n",
    "df_us_claims_grouped['claim_fulltext'] = df_us_claims_grouped.apply(process_row, axis=1)\n",
    "df_us_claims_grouped.drop('claim_text', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract EP Fulltext (Title, Abstract, Brf Summary, Claims, Description) - (currently only Title, Abstract, Claims considered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as connection:    \n",
    "    query_ep_fulltext_data = \"\"\"\n",
    "        SELECT t1.*, t2.*\n",
    "        FROM temp_appln_ids_with_publn t1 \n",
    "        JOIN ep_fulltext_data t2 \n",
    "            ON t1.publn_nr = t2.epo_publn_nr\n",
    "            AND t1.publn_auth = t2.publn_auth\n",
    "        WHERE t2.appln_lng = 'en'\n",
    "          AND t2.appln_comp = 'CLAIM';\n",
    "    \"\"\"\n",
    "    df_ep_fulltext_data = pd.read_sql(query_ep_fulltext_data, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = {'B9': 11, 'B8': 10, 'B3': 9, 'B2': 8, 'B1': 7, 'A9': 6, 'A8': 5, 'A4': 4, 'A3': 3, 'A2': 2, 'A1': 1}\n",
    "df_ep_fulltext_data['order'] = df_ep_fulltext_data['appln_kind'].map(order)\n",
    "df_ep_fulltext_data.drop(['epo_publn_nr', 'appln_auth', 'appln_date', 'appln_lng', 'appln_text_type'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ep_fulltext_data_claims = df_ep_fulltext_data[df_ep_fulltext_data['appln_comp'] == 'CLAIM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ep_fulltext_data_claims = df_ep_fulltext_data_claims.sort_values(by=['publn_nr', 'order'])\n",
    "df_ep_fulltext_data_claims = df_ep_fulltext_data_claims.groupby('publn_nr').first().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html(text):\n",
    "    cleaned_text = re.sub(r'<!--.*?-->', ' ', text)\n",
    "    soup = BeautifulSoup(cleaned_text, 'html.parser')\n",
    "    cleaned_text = soup.get_text(separator=' ')\n",
    "    return cleaned_text\n",
    "def clean_claim_text(claim_text):\n",
    "    # Remove all instances of <!--(.*?)-->\n",
    "    claim_text = re.sub(r'<!--.*?-->', ' ', claim_text)\n",
    "\n",
    "    # Parse the claim_text as XML using BeautifulSoup\n",
    "    soup = BeautifulSoup(claim_text, 'html.parser')\n",
    "    \n",
    "    # Extract all text from <claim-text> tags\n",
    "    cleaned_texts = [elem.get_text() for elem in soup.find_all('claim-text') if elem.get_text()]\n",
    "\n",
    "    # Join the cleaned texts\n",
    "    cleaned_text = ' '.join(cleaned_texts)\n",
    "    \n",
    "    return cleaned_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ep_fulltext_data_claims['appln_text'] = df_ep_fulltext_data_claims['appln_text'].apply(clean_claim_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ep_fulltext_data_claims = df_ep_fulltext_data_claims.loc[:, ~df_ep_fulltext_data_claims.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build one common dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.merge(df_grouped, df_cleantech_citations_agg, on='appln_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only needed columns from df_combined\n",
    "df_combined_subset = df_combined[['appln_id', 'cpc_class_symbol', 'publn_date', \n",
    "                                 'pat_publn_id', 'cited_pat_publn_id', 'cited_appln_id']]\n",
    "\n",
    "# Select only needed columns from df_title_abstr\n",
    "df_title_abstr_subset = df_title_abstr[['appln_id', 'publn_nr', 'publn_auth', \n",
    "                                        'appln_title', 'appln_abstract']]\n",
    "\n",
    "# Merge the subsets on appln_id\n",
    "df_combined = df_combined_subset.merge(df_title_abstr_subset, on='appln_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with df_us_claims_grouped on appln_id\n",
    "df_combined = df_combined.merge(df_us_claims_grouped, on='appln_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ep_fulltext_data_claims_subset = df_ep_fulltext_data_claims[['appln_id', 'appln_text']].copy()\n",
    "# Merge with df_ep_fulltext_data_claims_subset on appln_id\n",
    "df_combined = df_combined.merge(df_ep_fulltext_data_claims_subset, on='appln_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge columns claim_fulltext and appln_text\n",
    "df_combined['claim_fulltext'] = df_combined['claim_fulltext'].fillna(df_combined['appln_text'])\n",
    "df_combined.drop('appln_text', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with df_shortest_publn so that all column entries are filled\n",
    "df_combined_subset = df_combined[['appln_id', 'cpc_class_symbol', 'cited_pat_publn_id', 'cited_appln_id', 'appln_title', 'appln_abstract', 'claim_fulltext']].copy()\n",
    "df_combined = pd.merge(df_combined_subset, df_shortest_publn[['appln_id', 'publn_nr', 'publn_auth', 'publn_date', 'pat_publn_id']], on='appln_id', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = df_combined[['appln_id', 'publn_nr', 'publn_auth', 'publn_date', 'pat_publn_id', 'cpc_class_symbol', 'cited_pat_publn_id', 'cited_appln_id', 'appln_title', 'appln_abstract', 'claim_fulltext']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_parquet('/mnt/hdd02/Projekt_EDV_TEK/edv_tek_cleantech_patstat_diffusion.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Measures for Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of US patents with citations: 381540\n",
      "Number of EP patents with citations: 8085\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of patents with citations (for US and EP separately)\n",
    "us_patents_with_citations = df_combined[(df_combined['publn_auth'] == 'US') & \n",
    "                                        (df_combined['cited_pat_publn_id'].notna())].shape[0]\n",
    "print(f\"Number of US patents with citations: {us_patents_with_citations}\")\n",
    "\n",
    "ep_patents_with_citations = df_combined[(df_combined['publn_auth'] == 'EP') &\n",
    "                                        (df_combined['cited_pat_publn_id'].notna())].shape[0]\n",
    "print(f\"Number of EP patents with citations: {ep_patents_with_citations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "587781it [00:17, 33039.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total US patents analyzed: 587781\n",
      "US patents citing at least one EP patent: 1228\n",
      "Total citations from US to EP patents: 1363\n",
      "Percentage of US patents citing EP patents: 0.21%\n",
      "Average number of EP citations per US patent (that cites EP): 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter for US patents\n",
    "us_patents = df_combined[df_combined['publn_auth'] == 'US']\n",
    "\n",
    "# Create a mapping from appln_id to publn_auth\n",
    "appln_id_to_auth = dict(zip(df_combined['appln_id'], df_combined['publn_auth']))\n",
    "\n",
    "# Initialize counters\n",
    "us_to_ep_citations = 0\n",
    "us_patents_with_ep_citations = 0\n",
    "\n",
    "# Iterate through US patents\n",
    "for _, us_patent in tqdm(us_patents.iterrows()):\n",
    "    cited_appln_ids = us_patent['cited_appln_id']\n",
    "    \n",
    "    # Skip if there are no citations - fixed condition\n",
    "    if cited_appln_ids is None or isinstance(cited_appln_ids, float) and pd.isna(cited_appln_ids) or (isinstance(cited_appln_ids, list) and len(cited_appln_ids) == 0):\n",
    "        continue\n",
    "    \n",
    "    # Count EP citations in this patent\n",
    "    ep_citations_in_patent = 0\n",
    "    for app_id in cited_appln_ids:\n",
    "        if app_id in appln_id_to_auth and appln_id_to_auth[app_id] == 'EP':\n",
    "            ep_citations_in_patent += 1\n",
    "    \n",
    "    us_to_ep_citations += ep_citations_in_patent\n",
    "    if ep_citations_in_patent > 0:\n",
    "        us_patents_with_ep_citations += 1\n",
    "\n",
    "# Print results\n",
    "print(f\"Total US patents analyzed: {len(us_patents)}\")\n",
    "print(f\"US patents citing at least one EP patent: {us_patents_with_ep_citations}\")\n",
    "print(f\"Total citations from US to EP patents: {us_to_ep_citations}\")\n",
    "\n",
    "# Calculate statistics\n",
    "if len(us_patents) > 0:\n",
    "    print(f\"Percentage of US patents citing EP patents: {us_patents_with_ep_citations/len(us_patents)*100:.2f}%\")\n",
    "    \n",
    "if us_patents_with_ep_citations > 0:\n",
    "    print(f\"Average number of EP citations per US patent (that cites EP): {us_to_ep_citations/us_patents_with_ep_citations:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "182387it [00:04, 38205.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total EP patents analyzed: 182387\n",
      "EP patents citing at least one US patent: 8035\n",
      "Total citations from EP to US patents: 12892\n",
      "Percentage of EP patents citing US patents: 4.41%\n",
      "Average number of US citations per EP patent (that cites US): 1.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter for EP patents\n",
    "ep_patents = df_combined[df_combined['publn_auth'] == 'EP']\n",
    "\n",
    "# Create a mapping from appln_id to publn_auth\n",
    "appln_id_to_auth = dict(zip(df_combined['appln_id'], df_combined['publn_auth']))\n",
    "\n",
    "# Initialize counters\n",
    "ep_to_us_citations = 0\n",
    "ep_patents_with_us_citations = 0\n",
    "\n",
    "# Iterate through EP patents\n",
    "for _, ep_patent in tqdm(ep_patents.iterrows()):\n",
    "    cited_appln_ids = ep_patent['cited_appln_id']\n",
    "    \n",
    "    # Skip if there are no citations - fixed condition\n",
    "    if cited_appln_ids is None or isinstance(cited_appln_ids, float) and pd.isna(cited_appln_ids) or (isinstance(cited_appln_ids, list) and len(cited_appln_ids) == 0):\n",
    "        continue\n",
    "    \n",
    "    # Count US citations in this patent\n",
    "    us_citations_in_patent = 0\n",
    "    for app_id in cited_appln_ids:\n",
    "        if app_id in appln_id_to_auth and appln_id_to_auth[app_id] == 'US':\n",
    "            us_citations_in_patent += 1\n",
    "    \n",
    "    ep_to_us_citations += us_citations_in_patent\n",
    "    if us_citations_in_patent > 0:\n",
    "        ep_patents_with_us_citations += 1\n",
    "\n",
    "# Print results\n",
    "print(f\"Total EP patents analyzed: {len(ep_patents)}\")\n",
    "print(f\"EP patents citing at least one US patent: {ep_patents_with_us_citations}\")\n",
    "print(f\"Total citations from EP to US patents: {ep_to_us_citations}\")\n",
    "\n",
    "# Calculate statistics\n",
    "if len(ep_patents) > 0:\n",
    "    print(f\"Percentage of EP patents citing US patents: {ep_patents_with_us_citations/len(ep_patents)*100:.2f}%\")\n",
    "    \n",
    "if ep_patents_with_us_citations > 0:\n",
    "    print(f\"Average number of US citations per EP patent (that cites US): {ep_to_us_citations/ep_patents_with_us_citations:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest publication year: 1836\n",
      "Latest publication year: 2023\n",
      "Time span: 188 years\n",
      "\n",
      "Number of patents by year:\n",
      "publn_date\n",
      "1836        1\n",
      "1837        6\n",
      "1838        5\n",
      "1839        3\n",
      "1840        5\n",
      "        ...  \n",
      "2019    51237\n",
      "2020    49168\n",
      "2021    42646\n",
      "2022    35828\n",
      "2023     5126\n",
      "Name: count, Length: 188, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Handle both string and datetime formats\n",
    "if isinstance(df_combined['publn_date'].iloc[0], str):\n",
    "    # Convert string dates to datetime\n",
    "    date_series = pd.to_datetime(df_combined['publn_date'])\n",
    "else:\n",
    "    # Already datetime format\n",
    "    date_series = df_combined['publn_date']\n",
    "\n",
    "# Extract years from the datetime objects\n",
    "years = date_series.dt.year.dropna()\n",
    "\n",
    "# Find the min and max years\n",
    "if not years.empty:\n",
    "    earliest_year = int(years.min())\n",
    "    latest_year = int(years.max())\n",
    "    \n",
    "    print(f\"Earliest publication year: {earliest_year}\")\n",
    "    print(f\"Latest publication year: {latest_year}\")\n",
    "    print(f\"Time span: {latest_year - earliest_year + 1} years\")\n",
    "else:\n",
    "    print(\"No valid dates found in the dataset.\")\n",
    "\n",
    "# Optional: Show distribution of patents by year\n",
    "year_counts = years.value_counts().sort_index()\n",
    "print(\"\\nNumber of patents by year:\")\n",
    "print(year_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_combined['publn_date'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2008-10-08'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined['publn_date'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appln_id</th>\n",
       "      <th>publn_nr</th>\n",
       "      <th>publn_auth</th>\n",
       "      <th>publn_date</th>\n",
       "      <th>pat_publn_id</th>\n",
       "      <th>cpc_class_symbol</th>\n",
       "      <th>cited_pat_publn_id</th>\n",
       "      <th>cited_appln_id</th>\n",
       "      <th>appln_title</th>\n",
       "      <th>appln_abstract</th>\n",
       "      <th>claim_fulltext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101891</td>\n",
       "      <td>1360181</td>\n",
       "      <td>EP</td>\n",
       "      <td>2008-10-08</td>\n",
       "      <td>289379223</td>\n",
       "      <td>[Y02P  20/52]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>EPOXIDATION CATALYST AND PROCESS</td>\n",
       "      <td>In a process for the production of an oxirane ...</td>\n",
       "      <td>A process for the epoxidation bf an olefin by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101897</td>\n",
       "      <td>1333516</td>\n",
       "      <td>EP</td>\n",
       "      <td>2006-12-13</td>\n",
       "      <td>387634414</td>\n",
       "      <td>[Y02E  60/50]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Fuel cell and process for improving the transp...</td>\n",
       "      <td>The method involves generating pressure differ...</td>\n",
       "      <td>Method for improving a heat and mass transfer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101926</td>\n",
       "      <td>1711753</td>\n",
       "      <td>EP</td>\n",
       "      <td>2010-08-18</td>\n",
       "      <td>323646172</td>\n",
       "      <td>[Y02B  10/10, Y02B  10/20, Y02B  10/70, Y02E  ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>VACUUM-INSULATED, MODULAR ROOF SYSTEM</td>\n",
       "      <td>The invention relates to an insulated, modular...</td>\n",
       "      <td>Insulated modular roof system (100) comprising...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101976</td>\n",
       "      <td>2013456</td>\n",
       "      <td>EP</td>\n",
       "      <td>2010-10-13</td>\n",
       "      <td>327969544</td>\n",
       "      <td>[Y02T  10/12, Y02T  10/40]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>DEVICE FOR SUPPLYING A REDUCING AGENT INTO AN ...</td>\n",
       "      <td>The invention relates to a device (2) for supp...</td>\n",
       "      <td>Device for supplying a reducing agent into an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101984</td>\n",
       "      <td>2028791</td>\n",
       "      <td>EP</td>\n",
       "      <td>2012-07-04</td>\n",
       "      <td>365139097</td>\n",
       "      <td>[Y02D  30/00]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Recognition of incorrect configurations on net...</td>\n",
       "      <td>The method involves providing information of n...</td>\n",
       "      <td>Method for recognizing incorrect configuration...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  appln_id publn_nr publn_auth  publn_date pat_publn_id  \\\n",
       "0   101891  1360181         EP  2008-10-08    289379223   \n",
       "1   101897  1333516         EP  2006-12-13    387634414   \n",
       "2   101926  1711753         EP  2010-08-18    323646172   \n",
       "3   101976  2013456         EP  2010-10-13    327969544   \n",
       "4   101984  2028791         EP  2012-07-04    365139097   \n",
       "\n",
       "                                    cpc_class_symbol cited_pat_publn_id  \\\n",
       "0                                      [Y02P  20/52]               None   \n",
       "1                                      [Y02E  60/50]               None   \n",
       "2  [Y02B  10/10, Y02B  10/20, Y02B  10/70, Y02E  ...               None   \n",
       "3                         [Y02T  10/12, Y02T  10/40]               None   \n",
       "4                                      [Y02D  30/00]               None   \n",
       "\n",
       "  cited_appln_id                                        appln_title  \\\n",
       "0           None                   EPOXIDATION CATALYST AND PROCESS   \n",
       "1           None  Fuel cell and process for improving the transp...   \n",
       "2           None              VACUUM-INSULATED, MODULAR ROOF SYSTEM   \n",
       "3           None  DEVICE FOR SUPPLYING A REDUCING AGENT INTO AN ...   \n",
       "4           None  Recognition of incorrect configurations on net...   \n",
       "\n",
       "                                      appln_abstract  \\\n",
       "0  In a process for the production of an oxirane ...   \n",
       "1  The method involves generating pressure differ...   \n",
       "2  The invention relates to an insulated, modular...   \n",
       "3  The invention relates to a device (2) for supp...   \n",
       "4  The method involves providing information of n...   \n",
       "\n",
       "                                      claim_fulltext  \n",
       "0  A process for the epoxidation bf an olefin by ...  \n",
       "1  Method for improving a heat and mass transfer ...  \n",
       "2  Insulated modular roof system (100) comprising...  \n",
       "3  Device for supplying a reducing agent into an ...  \n",
       "4  Method for recognizing incorrect configuration...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edv_tek",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
